{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0242fc5f",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0a73ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48a39084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18245</td>\n",
       "      <td>This short spoof can be found on Elite's Mille...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19801</td>\n",
       "      <td>A singularly unfunny musical comedy that artif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3222</td>\n",
       "      <td>An excellent series, masterfully acted and dir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6010</td>\n",
       "      <td>The master of movie spectacle Cecil B. De Mill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16355</td>\n",
       "      <td>I was gifted with this movie as it had such a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>7334</td>\n",
       "      <td>Although this film is somewhat filled with eig...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>11638</td>\n",
       "      <td>Bo Derek's beauty and John Derek's revolutiona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>19851</td>\n",
       "      <td>I have seen every episode of this spin off. I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>8114</td>\n",
       "      <td>A comedy gem. Lots of laugh out loud moments, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7500</th>\n",
       "      <td>859</td>\n",
       "      <td>...about the importance of being young, having...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                             review  label\n",
       "0          18245  This short spoof can be found on Elite's Mille...      0\n",
       "1          19801  A singularly unfunny musical comedy that artif...      0\n",
       "2           3222  An excellent series, masterfully acted and dir...      1\n",
       "3           6010  The master of movie spectacle Cecil B. De Mill...      1\n",
       "4          16355  I was gifted with this movie as it had such a ...      0\n",
       "...          ...                                                ...    ...\n",
       "7496        7334  Although this film is somewhat filled with eig...      1\n",
       "7497       11638  Bo Derek's beauty and John Derek's revolutiona...      1\n",
       "7498       19851  I have seen every episode of this spin off. I ...      0\n",
       "7499        8114  A comedy gem. Lots of laugh out loud moments, ...      1\n",
       "7500         859  ...about the importance of being young, having...      1\n",
       "\n",
       "[7501 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('IMDB_sample.csv')\n",
    "movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd3551a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive and negative reviews: \n",
      "0    3782\n",
      "1    3719\n",
      "Name: label, dtype: int64\n",
      "Proportion of positive and negative reviews: \n",
      "0    0.504199\n",
      "1    0.495801\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find the number of positive and negative reviews\n",
    "print('Number of positive and negative reviews: ')\n",
    "print(movies.label.value_counts())\n",
    "\n",
    "# Find the proportion of positive and negative reviews\n",
    "print('Proportion of positive and negative reviews: ')\n",
    "print(movies.label.value_counts() / len(movies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "576e2dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7501\n"
     ]
    }
   ],
   "source": [
    "length_reviews = movies.review.str.len()\n",
    "\n",
    "# How long is the longest review\n",
    "print(len(length_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de562d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "length_reviews = movies.review.str.len()\n",
    "\n",
    "# How long is the shortest review\n",
    "print(min(length_reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b58c1746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 12:01:01 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:46 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:15 -0800</td>\n",
       "      <td>Nigeria,lagos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:02 -0800</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:58:51 -0800</td>\n",
       "      <td>dallas, TX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513           neutral                        1.0000   \n",
       "1      570301130888122368          positive                        0.3486   \n",
       "2      570301083672813571           neutral                        0.6837   \n",
       "3      570301031407624196          negative                        1.0000   \n",
       "4      570300817074462722          negative                        1.0000   \n",
       "...                   ...               ...                           ...   \n",
       "14635  569587686496825344          positive                        0.3487   \n",
       "14636  569587371693355008          negative                        1.0000   \n",
       "14637  569587242672398336           neutral                        1.0000   \n",
       "14638  569587188687634433          negative                        1.0000   \n",
       "14639  569587140490866689           neutral                        0.6771   \n",
       "\n",
       "               negativereason  negativereason_confidence         airline  \\\n",
       "0                         NaN                        NaN  Virgin America   \n",
       "1                         NaN                     0.0000  Virgin America   \n",
       "2                         NaN                        NaN  Virgin America   \n",
       "3                  Bad Flight                     0.7033  Virgin America   \n",
       "4                  Can't Tell                     1.0000  Virgin America   \n",
       "...                       ...                        ...             ...   \n",
       "14635                     NaN                     0.0000        American   \n",
       "14636  Customer Service Issue                     1.0000        American   \n",
       "14637                     NaN                        NaN        American   \n",
       "14638  Customer Service Issue                     0.6659        American   \n",
       "14639                     NaN                     0.0000        American   \n",
       "\n",
       "      airline_sentiment_gold             name negativereason_gold  \\\n",
       "0                        NaN          cairdin                 NaN   \n",
       "1                        NaN         jnardino                 NaN   \n",
       "2                        NaN       yvonnalynn                 NaN   \n",
       "3                        NaN         jnardino                 NaN   \n",
       "4                        NaN         jnardino                 NaN   \n",
       "...                      ...              ...                 ...   \n",
       "14635                    NaN  KristenReenders                 NaN   \n",
       "14636                    NaN         itsropes                 NaN   \n",
       "14637                    NaN         sanyabun                 NaN   \n",
       "14638                    NaN       SraJackson                 NaN   \n",
       "14639                    NaN        daviddtwu                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0                @VirginAmerica What @dhepburn said.   \n",
       "1                  0  @VirginAmerica plus you've added commercials t...   \n",
       "2                  0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                  0  @VirginAmerica it's really aggressive to blast...   \n",
       "4                  0  @VirginAmerica and it's a really big bad thing...   \n",
       "...              ...                                                ...   \n",
       "14635              0  @AmericanAir thank you we got on a different f...   \n",
       "14636              0  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637              0  @AmericanAir Please bring American Airlines to...   \n",
       "14638              0  @AmericanAir you have my money, you change my ...   \n",
       "14639              0  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "      tweet_coord              tweet_created tweet_location  \\\n",
       "0             NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1             NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2             NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3             NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4             NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "...           ...                        ...            ...   \n",
       "14635         NaN  2015-02-22 12:01:01 -0800            NaN   \n",
       "14636         NaN  2015-02-22 11:59:46 -0800          Texas   \n",
       "14637         NaN  2015-02-22 11:59:15 -0800  Nigeria,lagos   \n",
       "14638         NaN  2015-02-22 11:59:02 -0800     New Jersey   \n",
       "14639         NaN  2015-02-22 11:58:51 -0800     dallas, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0      Eastern Time (US & Canada)  \n",
       "1      Pacific Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4      Pacific Time (US & Canada)  \n",
       "...                           ...  \n",
       "14635                         NaN  \n",
       "14636                         NaN  \n",
       "14637                         NaN  \n",
       "14638  Eastern Time (US & Canada)  \n",
       "14639                         NaN  \n",
       "\n",
       "[14640 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e54ad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c812a0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image copyright EPA Image caption Uber has been criticised many times over the way it runs its business\n",
      "\n",
      "\n",
      "Ride-sharing firm Uber is facing a criminal investigation by the US government.\n",
      "\n",
      "\n",
      "The scrutiny has started because the firm is accused of using \"secret\" software that let it operate in regions where it was banned or restricted.\n",
      "\n",
      "\n",
      "The software, called \"greyball\", helped it identify officials seeking to stop the service running.\n",
      "\n",
      "\n",
      "A spokesman for Uber declined to comment on the investigation, reported the Reuters news agency.\n",
      "\n",
      "\n",
      "It is claimed greyball was used in several areas, including Portland, Oregon, where the ride service was still seeking official approval to operate.\n",
      "\n",
      "\n",
      "Bookings blocked\n",
      "\n",
      "\n",
      "In those areas, transport regulation officials posed as passengers in a bid to prove that the company was operating illegally. Greyball worked out who the officials were and blocked them from booking rides with the company's drivers.\n",
      "\n",
      "\n",
      "In a letter sent last week to transport regulators in Portland, Uber said it used the greyball software \"exceedingly sparingly\" in the city and had not used it since April 2015 when it was granted permission to operate.\n",
      "\n",
      "\n",
      "Uber's use of the software was revealed by the New York Times earlier this year. Uber defended its use in a blog saying the software helped it work out if a ride request was legitimate. It helped Uber limit fraud and protect drivers from harm, it added.\n",
      "\n",
      "\n",
      "It is not clear what sanctions Uber will face if the investigation finds that it did act illegally.\n",
      "\n",
      "\n",
      "The criminal inquiry comes at a difficult time for Uber which has faced criticism on many fronts. It is currently fighting a lawsuit from Google-backed self-driving car firm Waymo.Despite all the current hype about the rise of voice-assisted devices using Alexa and Siri, linguistics researcher Rachael Tatman found people complaining on social media that the technology still doesn’t understand them.\n",
      "\n",
      "\n",
      "That’s especially true with regional accents of people who live in the South or are from countries like New Zealand, Tatman said last week during a conference in San Francisco.\n",
      "\n",
      "\n",
      "“So this is the whatever the opposite of delight is as a user experience,” she said. “People are so upset that they’re going on Twitter and yelling about it.”\n",
      "\n",
      "\n",
      "Tatman, a doctoral candidate with the University of Washington’s linguistics department, was one of the speakers at a two-day Virtual Assistant Summit, which wrapped up Friday at the Park Central Hotel. The conference, and an adjacent Deep Learning Summit, drew about 600 people representing companies that are working on advancing artificial intelligence, machine learning and robotics.\n",
      "\n",
      "\n",
      "Lots of people are already using those technologies in programs like Apple’s Siri. They are moving beyond mobile phones and into smart-home devices like Amazon’s Echo. Other fast-changing technologies include artificial intelligence and consumer robotics, especially with self-driving cars on the horizon.\n",
      "\n",
      "\n",
      "But there’s still work to be done in each of those areas, speakers said. For example, artificial speech recognition technologies still fall short of the way humans can quickly learn and discern speech patterns from each other in “as little as two sentences,” Tatman said.\n",
      "\n",
      "\n",
      "But that’s because humans take into account other factors, such as the gender of person talking or whether they’ve previously met someone from the the same region, she said.\n",
      "\n",
      "\n",
      "Tatman examined YouTube’s automatic captioning program, which can translate spoken words into text in several languages. She found that more errors showed up in translations from speakers who had a Southern accent than from people who lived in California.\n",
      "\n",
      "\n",
      "“The South is the largest demographic region in the United States,” she said. “If you’re using a voice-based virtual assistant and you can’t deal with Southern speech, you’re going to have problems reaching this market.”\n",
      "\n",
      "\n",
      "For businesses trying to serve those markets, speech recognition technology could be crucial to future revenue, said Stephen Scarr, CEO of search services Info.com and eContext.\n",
      "\n",
      "\n",
      "With 20 percent of all searches already done through voice, “this is really important, this is No. 1 on your radar,” Scarr told the developers.\n",
      "\n",
      "\n",
      "As an example of the challenge, a recent YouTube video showed Amazon’s Alexa misunderstanding a young boy’s request to play a song, and instead offering to play an audio porn channel.\n",
      "\n",
      "\n",
      "The conference touched on more than just speech technologies. Alonso Martinez, a Pixar Animation Studios technical director, said robot developers could take cues from the ways animators create deep emotional connections with audiences.\n",
      "\n",
      "\n",
      "“When you’re thinking about a robot, don’t think about it as a generic, faceless thing,” said Martinez, who developed characters in “Up” and “Inside Out,” two of the Emeryville company’s hit movies. “You need to ask what makes them admirable. What are the values that they have that I wish that I had in myself?”\n",
      "\n",
      "\n",
      "Elena Corina Grigore of Yale University’s Social Robotics Lab said robots now used in manufacturing can work by themselves because they are easily trained to perform specialized, repetitive tasks. But robots are not well-equipped to collaborate with humans, she said.\n",
      "\n",
      "\n",
      "That’s slowly changing with advances in artificial intelligence. As an example, Grigore played a video of a robot trained to help a person with what can be a complex and maddening task — assembling a chair from Ikea.\n",
      "\n",
      "\n",
      "Still, Grigore said, “We’re not getting replaced by robots anytime soon. We’re not at a point where the robots have the intelligence or the physical capabilities necessary to perform all of these actions on their own. Anything that is related to common sense or creativity or types of thinking that require on-the-spot flexibility in a dynamic and changing environment is still very hard to achieve for us.”\n",
      "\n",
      "\n",
      "Benny Evangelista is a San Francisco Chronicle staff writer. Email: bevangelista@sfchronicle.com Twitter: @ChronicleBenny The French electorate heads to the polls in the second round of presidential elections on May 7, followed by votes in Britain and Germany in the coming months. Computer scientists, tech giants and start-ups are using sophisticated algorithms and reams of online data to quickly — and automatically — spot fake news faster than traditional fact-checking groups can.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "The goal, experts say, is to expand these digital tools across Europe, so the region can counter the fake news that caused so much confusion and anger during the United States presidential election in November, when outright false reports routinely spread like wildfire on Facebook and Twitter.\n",
      "\n",
      "\n",
      "“Algorithms will have to do a lot of the heavy lifting when it comes to fighting misinformation,” said Claire Wardle, head of strategy and research at First Draft News, a nonprofit organization that has teamed up with tech companies and newsrooms to debunk fake reports about elections in the United States and Europe. “It’s impossible to do all of this by hand.”\n",
      "\n",
      "\n",
      "Researchers have tried to learn from the United States’ run-in with fake news, but the problem in Europe has mutated, experts say, making it impossible to merely replicate American responses to the issue.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "European countries have different languages, and their media markets are smaller than those in the United States. That means groups that set up fake news sites in the United States, seeking to profit from online advertising when false claims were shared on social media, are less prevalent in Europe.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "So far, outright fake news stories have been relatively rare. Instead, false reports have more often come from Europeans on social media taking real news out of context, as well as from fake claims spread by state-backed groups like Sputnik, the Russian news organization.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "But with fake news already swirling around Europe’s forthcoming elections, analysts also worry that technology on its own may not be enough to combat the threat.\n",
      "\n",
      "\n",
      "“There’s an increased amount of misinformation out there,” said Janis Sarts, director of the NATO Strategic Communications Center of Excellence, a think tank in Riga, Latvia, that will hold a hackathon with local coders in May to find potential tech solutions to this trend. “State-based actors have been trying to amplify specific views to bring them into the mainstream.”\n",
      "\n",
      "\n",
      "Calls for combating fake news have focused on some of the biggest online players, including American giants like Facebook and Google.\n",
      "\n",
      "\n",
      "Interested in all things tech? The daily Bits newsletter will keep you updated on the latest from Silicon Valley and the technology industry, plus exclusive analysis from our reporters and editors. Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. Sign Up Receive occasional updates and special offers for The New York Times's products and services. Thank you for subscribing. An error has occurred. Please try again later. View all New York Times newsletters.\n",
      "\n",
      "\n",
      "After criticism of its role in spreading false reports during the United States elections, Facebook introduced a fact-checking tool ahead of the Dutch elections in March and the first round of the French presidential election on April 23. It also removed 30,000 accounts in France that had shared fake news, a small fraction of the approximately 33 million Facebook users in the country.\n",
      "\n",
      "\n",
      "Photo\n",
      "\n",
      "\n",
      "Not everyone, though, has embraced Facebook’s response.\n",
      "\n",
      "\n",
      "Most German publishers, for instance, have so far balked at participating in the company’s fact-checking efforts, saying it is the responsibility of the social network, not them, to debunk such claims. German lawmakers are mulling potential hefty fines against tech companies if they do not clamp down on fake news and online hate speech.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "Since last year, Google also has funded almost 20 European projects aimed at fact-checking potentially false reports. That includes its support for two British groups looking to use artificial intelligence to automatically fact-check online claims ahead of the country’s June 8 parliamentary election.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "It similarly has teamed up with French newsrooms to create digital tools, including ways to track trending topics during that country’s election.\n",
      "\n",
      "\n",
      "David Dieudonné, head of the company’s news lab in France, said the project had debunked 43 reports since February (arguably a relatively small figure), including claims that Saudi Arabia was funding the campaign of Emmanuel Macron, the leading candidate.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "“We’re trying something new,” Mr. Dieudonné said. “There’s no easy answer for this complicated issue.”\n",
      "\n",
      "\n",
      "Not all potential solutions, though, are being driven by Silicon Valley’s big beasts.\n",
      "\n",
      "\n",
      "David Chavalarias, a French academic, has created a digital tool that has analyzed more than 80 million Twitter messages about the French election, helping journalists and fact-checkers to quickly review claims that are spread on the social network.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "After the presidential election in the United States last year, Dean Pomerleau, a computer scientist at Carnegie Mellon University in Pittsburgh, also challenged his followers on Twitter to come up with an algorithm that could distinguish fake claims from real news.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "Working with Delip Rao, a former Google researcher, he offered a $2,000 prize to anyone who could meet his requirements. By early this year, more than 100 teams from around the world had signed on to Mr. Pomerleau’s Fake News Challenge.\n",
      "\n",
      "\n",
      "Using a database of verified articles and their artificial intelligence expertise, rival groups — a combination of college teams, independent programmers and groups from existing tech companies — already have been able to accurately predict the veracity of certain claims almost 90 percent of the time, Mr. Pomerleau said. He hopes that figure will rise to the mid-90s before his challenge ends in June.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "“This is just Round 1 of what we want to do,” said Mr. Pomerleau, who expects the teams to share their work with fact-checking groups worldwide. “Next, we want to move toward multimedia content like videos.”\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "In the rush to find solutions to fake news, some within the industry are taking a decidedly more low-tech approach.\n",
      "\n",
      "\n",
      "Jimmy Wales, the founder of Wikipedia, recently started a crowdfunding campaign to create a news organization that would combine professional journalists with digital volunteers, who would contribute to reports in a way similar to how articles are created on Wikipedia.\n",
      "\n",
      "\n",
      "Part fact-checking site, part traditional newsroom, the project — called Wikitribune — was inspired by the effect of misinformation on the United States presidential election. Mr. Wales said his project would choose subject areas based on the interests of the community of volunteers and paying subscribers to the service, relying more on traditional reporting techniques than high-tech wizardry.\n",
      "\n",
      "\n",
      "Advertisement Continue reading the main story\n",
      "\n",
      "\n",
      "“The real impetus for this was fake news,” he said. “We want people to get behind topics, and then we’ll hire staff to cover them.” Ruchir Sharma, chief global strategist at Morgan Stanley Investment Management, is the author of “The Rise and Fall of Nations: Forces of Change in the The Post-Crisis World,” from which this essay is adapted.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A robot collects dishes to be cleaned at Chilli Padi Nonya Cafe in Singapore. (REUTERS/Edgar Su)\n",
      "\n",
      "\n",
      "The United Nations forecasts that the global population will rise from 7.3 billion to nearly 10 billion by 2050, a big number that often prompts warnings about overpopulation. Some have come from neo-Malthusians, who fear that population growth will outstrip the food supply, leaving a hungry planet. Others appear in the tirades of anti-immigrant populists, invoking the specter of a rising tide of humanity as cause to slam borders shut. Still others inspire a chorus of neo-Luddites, who fear that the “rise of the robots” is rapidly making human workers obsolete, a threat all the more alarming if the human population is exploding.\n",
      "\n",
      "\n",
      "Before long, though, we’re more likely to treasure robots than to revile them. They may be the one thing that can protect the global economy from the dangers that lie ahead.\n",
      "\n",
      "\n",
      "An increase of 2.5 billion people may sound catastrophic. But what matters for economic growth is not the number of people but the rate of population growth. Since its peak in the 1960s, that rate has slumped by almost half to just 1 percent, and the U.N. forecast assumes that this slowdown will continue. Women are having fewer children, so fewer people are entering the working ages between 15 and 64, and labor-force growth is poised to decline from Chile to China. At the same time, owing to rapid advances in health care and medicine, people are living longer , and most of the coming global population increase will be among the retirement crowd. These trends are toxic for economic growth, and boosting the number of robots may be the easiest answer for many countries.\n",
      "\n",
      "\n",
      "One simple way to estimate how fast an economy can grow is by adding working-age population growth and productivity growth: If the number of workers and output per worker are both increasing by 1 percent a year, then economic output should rise by roughly 2 percent. Over the past decade, both sides of that equation have declined dramatically across the world. In the United States, productivity growth has fallen by almost half from its postwar average, but growth in the labor force has slid even faster, dropping by two-thirds to an average pace of 0.5 percent, according to calculations performed for my book. Though many explanations have been offered for the slow recovery from the global financial crisis of 2008, the clearest answer may be aging populations. Something will have to fill the void left by, say, retiring farmers, and particularly at a time of rising hostility to immigrants, it is likely to be farmbots.\n",
      "\n",
      "\n",
      "It may not be long before economists are worrying about a global shortage of robots. In many industrial countries, from Germany to Japan to South Korea, growth in the working-age population has already peaked, acting as a drag on the economy. Widely overlooked, however, is the fact that the population-growth slowdown is unfolding even faster in the emerging world, according to my research.\n",
      "\n",
      "\n",
      "Consider the turning point that China hit last year. For the first time since records began in the 1950s, its working-age population growth was negative. As a result, China’s labor force is expected to lose 1 million workers each year for the foreseeable future, and it is also aging rapidly. Studies by Evercore ISI, a research firm, show that the elderly share of the population is rising more than twice as fast as it did in the United States and more than four times faster than in France at similar stages of development. Asked by an alarmed dinner companion about the threat robots posed to jobs in China, Nobel economist Daniel Kahneman responded: “You just don’t get it. In China, the robots are going to come just in time.” No wonder Beijing now offers heavy subsidies to companies involved in industrial automation.\n",
      "\n",
      "\n",
      "And timing is critical. Those who fear the job-destroying impact of machines say this generation of technology is different because it is coming so fast. If older generations created tools for use by humans, such as sewing machines, the new forms of automation are imbued with artificial intelligence, capable of “machine learning” and of rapidly replacing humans in a broad swath of jobs, from manufacturing to services — even jobs that involve writing about robots. Concern about this disruptive advance has been stirred up by authorities such as Oxford University researchers Carl Benedikt Frey and Michael Osborne, who predicted in 2013 that nearly half of U.S. jobs would be at risk from automation in the next decade or two.\n",
      "\n",
      "\n",
      "These alarms have sounded before, however. The Machine Intelligence Research Institute at the University of California at Berkeley has found that today, the average forecast for when artificial intelligence will arrive is about 20 years. But that was also the standard prediction in 1955. And often, humans find a way of working with their automated creations. After the introduction of supermarket scanners, the number of cashiers grew. Though legal-discovery software appeared to threaten the jobs of paralegals, their ranks increased, too. Now, many fear that self-driving trucks will displace millions of American truckers, but they may create more and better jobs for those who service those increasingly complex vehicles.\n",
      "\n",
      "\n",
      "If automation was displacing human workers as fast as implied in recent books like Martin Ford’s “The Rise of the Robots,” then we should be seeing a negative impact on jobs already. We’re not. Since 2008, economic growth has been weak compared with that in other post-crisis recoveries, but job growth in the major industrial countries has been relatively strong. In the Group of Seven, the world’s top industrial countries, unemployment has fallen faster than expected in the face of weak economic growth, and faster than in any comparable period since at least the 1970s. The Japanese economy is growing at 0.8 percent, yet it is at full employment. According to my research, the job picture has been particularly strong in Germany, Japan and South Korea — the industrial countries that employ the most robots .\n",
      "\n",
      "\n",
      "True, robots do represent a new obstacle for some poorer nations, namely those few that do not suffer from population decline. In the postwar era, countries like China escaped poverty by moving a rising young population off the farm and into more productive jobs in factories. Indeed, it was unusual for any country to sustain rapid growth unless the working-age population was increasing faster than 2 percent a year. My analysis shows that, in the 1980s, 17 of the 20 largest emerging economies had a working-age population expanding that fast, according to my research, but now there are only two: Nigeria and Saudi Arabia. And they will have a hard time moving a large segment of their young populations into industrial jobs, given that they now have to compete with robotic manufacturing elsewhere.\n",
      "\n",
      "\n",
      "Yet for the rising number of countries facing population decline, the effort to lift the labor force has begun. Starting in the 1980s, led by Singapore, nations from Chile to Australia have offered baby bonuses for women to have more children, but many have found that these bonuses are ineffective in the face of stronger cultural forces, including the desire of many women to pursue a career before having children. Others have tried with some success to boost the workforce directly by raising the retirement age, offering women incentives to join or return to the labor force after having kids, and opening doors to immigrant workers.\n",
      "\n",
      "\n",
      "The simple math, however, shows that particularly in rapidly aging, conservative societies such as Japan and Germany, none of these groups has the potential to make up for coming declines in the working-age population. Germany decided to admit roughly 1 million refugees in 2015, in part for economic reasons, but the resulting controversy has reduced the flow. Germany would have to admit 1.5 million each year through 2030 to fully offset the economic impact of its aging population. Japan, which on average admits fewer than 70,000 immigrants per year, would have to admit 1 million annually. Given the widespread political backlash against immigration, increases this large are unlikely.\n",
      "\n",
      "\n",
      "So far, robots are drawing comparatively little populist fire, perhaps in part because their numbers are still quite low. Worldwide, the industrial labor force includes about 320 million humans, compared with just 1.6 million robots. That’s a huge gap, even counting the superior strength and speed of the robots. And most of them fall in the category of unintelligent machines, committed to a single task such as turning a bolt or painting a car door. Nearly half of them work in the auto industry, which is still the largest employer (of humans) in the United States.\n",
      "\n",
      "\n",
      "In the future, economists may start counting robots the way they now count gains in the working-age population, as a driver of growth. For much of the world, robots will stand alongside immigrants, women and the elderly as a fourth pool of labor.\n",
      "\n",
      "\n",
      "Whether by design or accident, many of the countries with the most rapidly aging populations already have the most robots. According to the International Federation of Robotics, the nations with the highest density of industrial robots include South Korea, with 531 per 10,000 employees, Japan with 305 and Germany with 301. The United States ranks eighth with 176. China is well behind with only 49, but on the bright side — arguably — it had the world’s fastest-growing robot population.\n",
      "\n",
      "\n",
      "Today, population trends are the most powerful force shaping the rise and fall of nations, the starting point of any discussion about an economy’s prospects. Most of the world is graying fast, and the economic answer to aging will be all hands on deck, no matter what they’re made of. Researchers describe the ‘emotional chatting machine’ as a first attempt at the problem of creating machines that can fully understand user emotion\n",
      "\n",
      "\n",
      "An “emotional chatting machine” has been developed by scientists, signalling the approach of an era in which human-robot interactions are seamless and go beyond the purely functional.\n",
      "\n",
      "\n",
      "The chatbot, developed by a Chinese team, is seen as a significant step towards the goal of developing emotionally sophisticated robots.\n",
      "\n",
      "\n",
      "The ECM, as it is known for short, was able to produce factually coherent answers whilst also imbuing its conversation with emotions such as happiness, sadness or disgust.\n",
      "\n",
      "\n",
      "Prof Björn Schuller, a computer scientist at Imperial College London who was not involved in the latest advance, described the work as “an important step” towards personal assistants that could read the emotional undercurrent of a conversation and respond with something akin to empathy.\n",
      "\n",
      "\n",
      "“This will be the next generation of intelligence to be met in daily experience, sooner rather than later,” he said.\n",
      "\n",
      "\n",
      "The paper found that 61% of humans who tested the machine favoured the emotional versions to the neutral chatbot. Similar results have been found in so-called “Wizard of Oz” studies in which a human typing responses masquerades as advanced AI.\n",
      "\n",
      "\n",
      "“It is not a question whether they are desirable – they clearly are – but in which applications they make sense and where they don’t,” said Schuller.\n",
      "\n",
      "\n",
      "Minlie Huang, a computer scientist at Tsinghua University, Beijing and co-author, said: “We’re still far away from a machine that can fully understand the user’s emotion. This is just the first attempt at this problem.”\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Huang and colleagues started by creating an “emotion classifying” algorithm that learned to detect emotion from 23,000 posts taken from the Chinese social media site Weibo. The posts had been manually classified by humans as sad, happy and so on.\n",
      "\n",
      "\n",
      "The emotion classifier was then used to tag millions of social media interactions according to emotional content. This huge dataset served as a training ground for the chatbot to learn both how to answer questions and how to express emotion.\n",
      "\n",
      "\n",
      "The resulting program could be switched into five possible modes – happy, sad, angry, disgusted, liking – depending on the user’s preference. In one example conversation a user typed in: “Worst day ever. I arrived late because of the traffic.”\n",
      "\n",
      "\n",
      "In neutral mode, the chatbot droned: “You were late”. Alternative responses were: “Sometimes life just sucks!” (disgust mode), “I am always here to support you” (liking) or “Keep smiling! Things will get better” (happy – or, some might say, annoyingly chipper).\n",
      "\n",
      "\n",
      "In the future, the team predict the software could also learn the appropriate emotion to express at a given time. “It could be mostly empathic,” said Huang, adding that a challenge would be to avoid the chatbot reinforcing negative feelings such as rage.\n",
      "\n",
      "\n",
      "Until recently chatbots were widely regarded as a sideshow to more serious attempts at tackling machine intelligence. A chatbot known as Eugene Goostman managed to convince some judges they were talking to a human – but only by posing as a 13-year old Ukrainian boy with a limited grasp of English. Microsoft’s disastrous chatbot Tay was supposed to learn to chat from Twitter interactions, but was terminated after becoming a genocide-supporting Nazi less than 24 hours after being let loose on the internet.\n",
      "\n",
      "\n",
      "The latest study shows that chatbots, driven by a machine learning approach, are starting to make significant headway. Sandra Wachter, a computer scientist at the Oxford Internet Institute, said that in future such algorithms are likely to be personalised. “Some of us prefer a tough-love pep talk, others prefer someone to rant with,” she said. “Humans often struggle with appropriate responses because of the complexity of emotions, so building technologies that could decipher accurately our ‘emotional code’ would be very impressive.”\n",
      "\n",
      "\n",
      "As the stilted computer interactions of today are replaced by something approaching friendly chit-chat, new risks could be encountered.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "One concern is the potential for technology designed to seduce the user into sharing sensitive personal data. “It could be that children share insights with their ‘artificial friends’ and this data might be stored,” said Wachter. “What if we were to find out that people are more likely to buy more products when they are angry, sad, or bored? The ability to detect these emotions and successfully manipulate them could be a very interesting tool for companies.”\n",
      "\n",
      "\n",
      "There is also the potential for users to become emotionally dependent, or even romantically involved, with their computers.\n",
      "\n",
      "\n",
      "“However, there is also a huge potential for good, such as existing software to teach children on the autism spectrum [about] emotional and social interaction,” said Schuller. “One has to carefully balance benefits and risks and ensure the best exploitation.”\n"
     ]
    }
   ],
   "source": [
    "# Open the text file for reading\n",
    "with open('articles.txt', 'r') as file:\n",
    "    # Read the contents of the file into a variable\n",
    "    art = file.read()\n",
    "\n",
    "# Print the contents of the file\n",
    "print(art)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5b837c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.029786934229198803, subjectivity=0.46342586474312947)\n"
     ]
    }
   ],
   "source": [
    "# Create a textblob object  \n",
    "blob_art = TextBlob(art)\n",
    "\n",
    "# Print out the sentiment \n",
    "print(blob_art.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5c330e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment of Articles:  Sentiment(polarity=0.029786934229198803, subjectivity=0.46342586474312947)\n"
     ]
    }
   ],
   "source": [
    "# Create a textblob object \n",
    "blob_art = TextBlob(art)\n",
    "\n",
    "# Print out the sentiment   \n",
    "print('Sentiment of Articles: ', blob_art.sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f14a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f387b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate the word cloud from the east_of_eden string\n",
    "# cloud_east_of_eden = WordCloud(background_color=\"white\").generate(east_of_eden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e32550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate the word cloud from the east_of_eden string\n",
    "# cloud_east_of_eden = WordCloud(background_color=\"white\").generate(east_of_eden)\n",
    "\n",
    "# # Create a figure of the generated cloud\n",
    "# plt.imshow(cloud_east_of_eden, interpolation='bilinear')  \n",
    "# plt.axis('off')\n",
    "# # Display the figure\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46758bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and generate a word cloud image \n",
    "# my_cloud = WordCloud(background_color='white', stopwords=my_stopwords).generate(descriptions)\n",
    "\n",
    "# # Display the generated wordcloud image\n",
    "# plt.imshow(my_cloud, interpolation='bilinear') \n",
    "# plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be450eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required function\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "201bb80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 1 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 1 1 1 1 2 1]]\n"
     ]
    }
   ],
   "source": [
    "annak = ['Happy families are all alike;', 'every unhappy family is unhappy in its own way']\n",
    "\n",
    "# Build the vectorizer and fit it\n",
    "anna_vect = CountVectorizer(max_features = 1000)\n",
    "anna_vect.fit(annak)\n",
    "\n",
    "# Create the bow representation\n",
    "anna_bow = anna_vect.transform(annak)\n",
    "\n",
    "# Print the bag-of-words result \n",
    "print(anna_bow.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "652d5c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>score</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>A revelation of life in small town America in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>1</td>\n",
       "      <td>Great biography of a very interesting journal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>0</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>0</td>\n",
       "      <td>Don't buy: The box looked used and it is obvi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>1</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  score                                             review\n",
       "0              0      1   Stuning even for the non-gamer: This sound tr...\n",
       "1              1      1   The best soundtrack ever to anything.: I'm re...\n",
       "2              2      1   Amazing!: This soundtrack is my favorite musi...\n",
       "3              3      1   Excellent Soundtrack: I truly like this sound...\n",
       "4              4      1   Remember, Pull Your Jaw Off The Floor After H...\n",
       "...          ...    ...                                                ...\n",
       "9995        9995      1   A revelation of life in small town America in...\n",
       "9996        9996      1   Great biography of a very interesting journal...\n",
       "9997        9997      0   Interesting Subject; Poor Presentation: You'd...\n",
       "9998        9998      0   Don't buy: The box looked used and it is obvi...\n",
       "9999        9999      1   Beautiful Pen and Fast Delivery.: The pen was...\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('amazon_reviews_sample.csv')\n",
    "reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "309eabbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   about  after  all  also  am  an  and  any  are  as  ...  what  when  which  \\\n",
      "0      0      0    1     0   0   0    2    0    0   0  ...     0     0      0   \n",
      "1      0      0    0     0   0   0    3    1    1   0  ...     0     0      0   \n",
      "2      0      0    3     0   0   1    4    0    1   1  ...     0     0      1   \n",
      "3      0      0    0     0   0   0    9    0    1   0  ...     0     0      0   \n",
      "4      0      1    0     0   0   0    3    0    1   0  ...     0     0      0   \n",
      "\n",
      "   who  will  with  work  would  you  your  \n",
      "0    2     0     1     0      2    0     1  \n",
      "1    0     0     0     0      1    1     0  \n",
      "2    1     0     0     1      1    2     0  \n",
      "3    0     0     0     0      0    0     0  \n",
      "4    0     0     0     0      0    3     1  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build the vectorizer, specify max features \n",
    "vect = CountVectorizer(max_features=100)\n",
    "\n",
    "# Fit the vectorizer\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df=pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f57a5ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  00 and  00 apiece  00 as  00 back  00 bad  00 bucks  00 cheaper  00 do  \\\n",
      "0   0       0          0      0        0       0         0           0      0   \n",
      "1   0       0          0      0        0       0         0           0      0   \n",
      "2   0       0          0      0        0       0         0           0      0   \n",
      "3   0       0          0      0        0       0         0           0      0   \n",
      "4   0       0          0      0        0       0         0           0      0   \n",
      "\n",
      "   00 does  ...  étai fidèle  était  était pas  étre  étre publié  éviter  \\\n",
      "0        0  ...            0      0          0     0            0       0   \n",
      "1        0  ...            0      0          0     0            0       0   \n",
      "2        0  ...            0      0          0     0            0       0   \n",
      "3        0  ...            0      0          0     0            0       0   \n",
      "4        0  ...            0      0          0     0            0       0   \n",
      "\n",
      "   última  última parte  única  única opción  \n",
      "0       0             0      0             0  \n",
      "1       0             0      0             0  \n",
      "2       0             0      0             0  \n",
      "3       0             0      0             0  \n",
      "4       0             0      0             0  \n",
      "\n",
      "[5 rows x 326726 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build the vectorizer, specify token sequence and fit\n",
    "vect = CountVectorizer(ngram_range=(1, 2))\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c1e93e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   20  acted  actual  america  animation  baby  begin  british  business  \\\n",
      "0   0      0       0        0          0     0      0        0         0   \n",
      "1   0      0       0        0          0     1      0        0         0   \n",
      "2   0      1       0        0          0     0      0        1         0   \n",
      "3   0      0       0        0          0     0      0        0         0   \n",
      "4   0      0       0        0          0     2      0        0         0   \n",
      "\n",
      "   check  ...  thriller  tom  total  truth  unique  weak  weird  worked  york  \\\n",
      "0      0  ...         0    0      0      0       0     0      0       0     0   \n",
      "1      0  ...         0    1      0      0       0     0      0       0     0   \n",
      "2      0  ...         0    0      0      0       0     0      0       0     0   \n",
      "3      0  ...         0    0      0      0       0     0      0       0     0   \n",
      "4      0  ...         0    0      0      0       0     0      0       0     0   \n",
      "\n",
      "   zombie  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       0  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build and fit the vectorizer\n",
    "vect = CountVectorizer(max_features=100,max_df=200,min_df=50)\n",
    "vect.fit(movies.review)\n",
    "\n",
    "# Transform the review column\n",
    "X_review = vect.transform(movies.review)\n",
    "\n",
    "# Create the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae0a2999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   able to  about how  about it  about the  about this  after reading  \\\n",
      "0        0          0         0          0           0              0   \n",
      "1        0          0         0          0           0              0   \n",
      "2        0          0         0          0           0              0   \n",
      "3        0          0         0          0           0              0   \n",
      "4        0          0         0          0           0              0   \n",
      "\n",
      "   after the  again and  ago and  agree with  ...  you think  you to  you ve  \\\n",
      "0          0          0        0           0  ...          0       0       0   \n",
      "1          0          0        0           0  ...          0       0       0   \n",
      "2          0          0        0           0  ...          0       0       2   \n",
      "3          0          0        0           0  ...          0       0       0   \n",
      "4          0          0        0           0  ...          0       0       1   \n",
      "\n",
      "   you want  you will  you won  you would  your money  your own  your time  \n",
      "0         0         0        0          0           0         0          0  \n",
      "1         0         0        0          0           0         0          0  \n",
      "2         0         0        0          0           0         0          0  \n",
      "3         0         0        0          0           0         0          0  \n",
      "4         0         0        0          0           0         0          0  \n",
      "\n",
      "[5 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "# Build the vectorizer, specify max features and fit\n",
    "vect = CountVectorizer(max_features=1000, ngram_range=(2, 2), max_df=500)\n",
    "vect.fit(reviews.review)\n",
    "\n",
    "# Transform the review\n",
    "X_review = vect.transform(reviews.review)\n",
    "\n",
    "# Create a DataFrame from the bow representation\n",
    "X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names_out())\n",
    "print(X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f95af14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "édition abonné\n",
      "\n",
      "\n",
      "Dans une tribune au « Monde », l’universitaire Charles Cuvelliez estime que le fantasme d’un remplacement de l’homme par l’algorithme et le robot repose sur un malentendu.\n",
      "\n",
      "\n",
      "Le Monde | 10.05.2017 à 06h44 • Mis à jour le 10.05.2017 à 09h47 | Par Charles Cuvelliez (Professeur à l’Ecole polytechnique de l'université libre de Bruxelles)\n",
      "\n",
      "\n",
      "TRIBUNE. L’usage morbide, par certains, de Facebook Live a amené son fondateur à annoncer précipitamment le recrutement de 3 000 modérateurs supplémentaires. Il est vrai que l’intelligence artificielle (IA) est bien en peine de reconnaître des contenus violents, surtout diffusés en direct.\n",
      "\n",
      "\n",
      "Le quotidien affreux de ces modérateurs, contraints de visionner des horreurs à longueur de journée, mériterait pourtant qu’on les remplace vite par des machines !\n",
      "\n",
      "\n",
      "L’IA ne peut pas tout, mais là où elle peut beaucoup, on la maudit, accusée de détruire nos emplois, de remplacer la convivialité humaine. Ce débat repose sur un malentendu.\n",
      "\n",
      "\n",
      "Il vient d’une définition de l’IA qui n’a, dans la réalité, jamais pu être mise en pratique : en 1955, elle était vue comme la création de programmes informatiques qui, quoi qu’on leur confie, le feraient un jour mieux que les humains. On pensait que toute caractéristique de l’intelligence humaine pourrait un jour être si précisément décrite qu’il suffirait d’une machine pour la simuler. Ce n’est pas vrai.\n",
      "\n",
      "\n",
      "Angoisses infondées\n",
      "\n",
      "\n",
      "Comme le dit un récent Livre blanc sur la question (Pourquoi il ne faut pas avoir peur de l’Intelligence arti­ficielle, Julien Maldonato, Deloitte, mars 2017), rien ne pourra remplacer un humain dans sa globalité.\n",
      "\n",
      "\n",
      "L’IA, c’est de l’apprentissage automatique doté d’un processus d’ajustement de modèles statistiques à des masses de données, explique l’auteur. Il s’agit d’un apprentissage sur des paramètres pour lesquels une vision humaine n’explique pas pourquoi ils marchent si bien dans un contexte donné.\n",
      "\n",
      "\n",
      "C’est aussi ce que dit le rapport de l’Office parlementaire d’évaluation des choix scientifiques et technologiques (« Pour une intelligence artificielle maîtrisée, utile et démystifiée », 29 mars 2017), pour qui ce côté « boîte noire » explique des angoisses infondées. Ethiquement, se fonder sur l’IA pour des tâches critiques sans bien comprendre le comment...\n"
     ]
    }
   ],
   "source": [
    "# Open the text file for reading\n",
    "with open('french.txt', 'r') as file:\n",
    "    # Read the contents of the file into a variable\n",
    "    french = file.read()\n",
    "\n",
    "# Print the contents of the file\n",
    "print(french)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8aafd65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required function\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c03d337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\ufeffédition', 'abonné', 'Dans', 'une', 'tribune', 'au', '«', 'Monde', '»', ',', 'l', '’', 'universitaire', 'Charles', 'Cuvelliez', 'estime', 'que', 'le', 'fantasme', 'd', '’', 'un', 'remplacement', 'de', 'l', '’', 'homme', 'par', 'l', '’', 'algorithme', 'et', 'le', 'robot', 'repose', 'sur', 'un', 'malentendu', '.', 'Le', 'Monde', '|', '10.05.2017', 'à', '06h44', '•', 'Mis', 'à', 'jour', 'le', '10.05.2017', 'à', '09h47', '|', 'Par', 'Charles', 'Cuvelliez', '(', 'Professeur', 'à', 'l', '’', 'Ecole', 'polytechnique', 'de', \"l'université\", 'libre', 'de', 'Bruxelles', ')', 'TRIBUNE', '.', 'L', '’', 'usage', 'morbide', ',', 'par', 'certains', ',', 'de', 'Facebook', 'Live', 'a', 'amené', 'son', 'fondateur', 'à', 'annoncer', 'précipitamment', 'le', 'recrutement', 'de', '3', '000', 'modérateurs', 'supplémentaires', '.', 'Il', 'est', 'vrai', 'que', 'l', '’', 'intelligence', 'artificielle', '(', 'IA', ')', 'est', 'bien', 'en', 'peine', 'de', 'reconnaître', 'des', 'contenus', 'violents', ',', 'surtout', 'diffusés', 'en', 'direct', '.', 'Le', 'quotidien', 'affreux', 'de', 'ces', 'modérateurs', ',', 'contraints', 'de', 'visionner', 'des', 'horreurs', 'à', 'longueur', 'de', 'journée', ',', 'mériterait', 'pourtant', 'qu', '’', 'on', 'les', 'remplace', 'vite', 'par', 'des', 'machines', '!', 'L', '’', 'IA', 'ne', 'peut', 'pas', 'tout', ',', 'mais', 'là', 'où', 'elle', 'peut', 'beaucoup', ',', 'on', 'la', 'maudit', ',', 'accusée', 'de', 'détruire', 'nos', 'emplois', ',', 'de', 'remplacer', 'la', 'convivialité', 'humaine', '.', 'Ce', 'débat', 'repose', 'sur', 'un', 'malentendu', '.', 'Il', 'vient', 'd', '’', 'une', 'définition', 'de', 'l', '’', 'IA', 'qui', 'n', '’', 'a', ',', 'dans', 'la', 'réalité', ',', 'jamais', 'pu', 'être', 'mise', 'en', 'pratique', ':', 'en', '1955', ',', 'elle', 'était', 'vue', 'comme', 'la', 'création', 'de', 'programmes', 'informatiques', 'qui', ',', 'quoi', 'qu', '’', 'on', 'leur', 'confie', ',', 'le', 'feraient', 'un', 'jour', 'mieux', 'que', 'les', 'humains', '.', 'On', 'pensait', 'que', 'toute', 'caractéristique', 'de', 'l', '’', 'intelligence', 'humaine', 'pourrait', 'un', 'jour', 'être', 'si', 'précisément', 'décrite', 'qu', '’', 'il', 'suffirait', 'd', '’', 'une', 'machine', 'pour', 'la', 'simuler', '.', 'Ce', 'n', '’', 'est', 'pas', 'vrai', '.', 'Angoisses', 'infondées', 'Comme', 'le', 'dit', 'un', 'récent', 'Livre', 'blanc', 'sur', 'la', 'question', '(', 'Pourquoi', 'il', 'ne', 'faut', 'pas', 'avoir', 'peur', 'de', 'l', '’', 'Intelligence', 'arti\\xadficielle', ',', 'Julien', 'Maldonato', ',', 'Deloitte', ',', 'mars', '2017', ')', ',', 'rien', 'ne', 'pourra', 'remplacer', 'un', 'humain', 'dans', 'sa', 'globalité', '.', 'L', '’', 'IA', ',', 'c', '’', 'est', 'de', 'l', '’', 'apprentissage', 'automatique', 'doté', 'd', '’', 'un', 'processus', 'd', '’', 'ajustement', 'de', 'modèles', 'statistiques', 'à', 'des', 'masses', 'de', 'données', ',', 'explique', 'l', '’', 'auteur', '.', 'Il', 's', '’', 'agit', 'd', '’', 'un', 'apprentissage', 'sur', 'des', 'paramètres', 'pour', 'lesquels', 'une', 'vision', 'humaine', 'n', '’', 'explique', 'pas', 'pourquoi', 'ils', 'marchent', 'si', 'bien', 'dans', 'un', 'contexte', 'donné', '.', 'C', '’', 'est', 'aussi', 'ce', 'que', 'dit', 'le', 'rapport', 'de', 'l', '’', 'Office', 'parlementaire', 'd', '’', 'évaluation', 'des', 'choix', 'scientifiques', 'et', 'technologiques', '(', '«', 'Pour', 'une', 'intelligence', 'artificielle', 'maîtrisée', ',', 'utile', 'et', 'démystifiée', '»', ',', '29', 'mars', '2017', ')', ',', 'pour', 'qui', 'ce', 'côté', '«', 'boîte', 'noire', '»', 'explique', 'des', 'angoisses', 'infondées', '.', 'Ethiquement', ',', 'se', 'fonder', 'sur', 'l', '’', 'IA', 'pour', 'des', 'tâches', 'critiques', 'sans', 'bien', 'comprendre', 'le', 'comment', '...']\n"
     ]
    }
   ],
   "source": [
    "# Transform the string to word tokens\n",
    "print(word_tokenize(french))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ab55b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\ufeff'], ['é'], ['d'], ['i'], ['t'], ['i'], ['o'], ['n'], [], ['a'], ['b'], ['o'], ['n'], ['n'], ['é'], [], [], [], ['D'], ['a'], ['n'], ['s'], [], ['u'], ['n'], ['e'], [], ['t'], ['r'], ['i'], ['b'], ['u'], ['n'], ['e'], [], ['a'], ['u'], [], ['«'], [], ['M'], ['o'], ['n'], ['d'], ['e'], [], ['»'], [','], [], ['l'], ['’'], ['u'], ['n'], ['i'], ['v'], ['e'], ['r'], ['s'], ['i'], ['t'], ['a'], ['i'], ['r'], ['e'], [], ['C'], ['h'], ['a'], ['r'], ['l'], ['e'], ['s'], [], ['C'], ['u'], ['v'], ['e'], ['l'], ['l'], ['i'], ['e'], ['z'], [], ['e'], ['s'], ['t'], ['i'], ['m'], ['e'], [], ['q'], ['u'], ['e'], [], ['l'], ['e'], [], ['f'], ['a'], ['n'], ['t'], ['a'], ['s'], ['m'], ['e'], [], ['d'], ['’'], ['u'], ['n'], [], ['r'], ['e'], ['m'], ['p'], ['l'], ['a'], ['c'], ['e'], ['m'], ['e'], ['n'], ['t'], [], ['d'], ['e'], [], ['l'], ['’'], ['h'], ['o'], ['m'], ['m'], ['e'], [], ['p'], ['a'], ['r'], [], ['l'], ['’'], ['a'], ['l'], ['g'], ['o'], ['r'], ['i'], ['t'], ['h'], ['m'], ['e'], [], ['e'], ['t'], [], ['l'], ['e'], [], ['r'], ['o'], ['b'], ['o'], ['t'], [], ['r'], ['e'], ['p'], ['o'], ['s'], ['e'], [], ['s'], ['u'], ['r'], [], ['u'], ['n'], [], ['m'], ['a'], ['l'], ['e'], ['n'], ['t'], ['e'], ['n'], ['d'], ['u'], ['.'], [], [], [], ['L'], ['e'], [], ['M'], ['o'], ['n'], ['d'], ['e'], [], ['|'], [], ['1'], ['0'], ['.'], ['0'], ['5'], ['.'], ['2'], ['0'], ['1'], ['7'], [], ['à'], [], ['0'], ['6'], ['h'], ['4'], ['4'], [], ['•'], [], ['M'], ['i'], ['s'], [], ['à'], [], ['j'], ['o'], ['u'], ['r'], [], ['l'], ['e'], [], ['1'], ['0'], ['.'], ['0'], ['5'], ['.'], ['2'], ['0'], ['1'], ['7'], [], ['à'], [], ['0'], ['9'], ['h'], ['4'], ['7'], [], ['|'], [], ['P'], ['a'], ['r'], [], ['C'], ['h'], ['a'], ['r'], ['l'], ['e'], ['s'], [], ['C'], ['u'], ['v'], ['e'], ['l'], ['l'], ['i'], ['e'], ['z'], [], ['('], ['P'], ['r'], ['o'], ['f'], ['e'], ['s'], ['s'], ['e'], ['u'], ['r'], [], ['à'], [], ['l'], ['’'], ['E'], ['c'], ['o'], ['l'], ['e'], [], ['p'], ['o'], ['l'], ['y'], ['t'], ['e'], ['c'], ['h'], ['n'], ['i'], ['q'], ['u'], ['e'], [], ['d'], ['e'], [], ['l'], [\"'\"], ['u'], ['n'], ['i'], ['v'], ['e'], ['r'], ['s'], ['i'], ['t'], ['é'], [], ['l'], ['i'], ['b'], ['r'], ['e'], [], ['d'], ['e'], [], ['B'], ['r'], ['u'], ['x'], ['e'], ['l'], ['l'], ['e'], ['s'], [')'], [], [], [], ['T'], ['R'], ['I'], ['B'], ['U'], ['N'], ['E'], ['.'], [], ['L'], ['’'], ['u'], ['s'], ['a'], ['g'], ['e'], [], ['m'], ['o'], ['r'], ['b'], ['i'], ['d'], ['e'], [','], [], ['p'], ['a'], ['r'], [], ['c'], ['e'], ['r'], ['t'], ['a'], ['i'], ['n'], ['s'], [','], [], ['d'], ['e'], [], ['F'], ['a'], ['c'], ['e'], ['b'], ['o'], ['o'], ['k'], [], ['L'], ['i'], ['v'], ['e'], [], ['a'], [], ['a'], ['m'], ['e'], ['n'], ['é'], [], ['s'], ['o'], ['n'], [], ['f'], ['o'], ['n'], ['d'], ['a'], ['t'], ['e'], ['u'], ['r'], [], ['à'], [], ['a'], ['n'], ['n'], ['o'], ['n'], ['c'], ['e'], ['r'], [], ['p'], ['r'], ['é'], ['c'], ['i'], ['p'], ['i'], ['t'], ['a'], ['m'], ['m'], ['e'], ['n'], ['t'], [], ['l'], ['e'], [], ['r'], ['e'], ['c'], ['r'], ['u'], ['t'], ['e'], ['m'], ['e'], ['n'], ['t'], [], ['d'], ['e'], [], ['3'], [], ['0'], ['0'], ['0'], [], ['m'], ['o'], ['d'], ['é'], ['r'], ['a'], ['t'], ['e'], ['u'], ['r'], ['s'], [], ['s'], ['u'], ['p'], ['p'], ['l'], ['é'], ['m'], ['e'], ['n'], ['t'], ['a'], ['i'], ['r'], ['e'], ['s'], ['.'], [], ['I'], ['l'], [], ['e'], ['s'], ['t'], [], ['v'], ['r'], ['a'], ['i'], [], ['q'], ['u'], ['e'], [], ['l'], ['’'], ['i'], ['n'], ['t'], ['e'], ['l'], ['l'], ['i'], ['g'], ['e'], ['n'], ['c'], ['e'], [], ['a'], ['r'], ['t'], ['i'], ['f'], ['i'], ['c'], ['i'], ['e'], ['l'], ['l'], ['e'], [], ['('], ['I'], ['A'], [')'], [], ['e'], ['s'], ['t'], [], ['b'], ['i'], ['e'], ['n'], [], ['e'], ['n'], [], ['p'], ['e'], ['i'], ['n'], ['e'], [], ['d'], ['e'], [], ['r'], ['e'], ['c'], ['o'], ['n'], ['n'], ['a'], ['î'], ['t'], ['r'], ['e'], [], ['d'], ['e'], ['s'], [], ['c'], ['o'], ['n'], ['t'], ['e'], ['n'], ['u'], ['s'], [], ['v'], ['i'], ['o'], ['l'], ['e'], ['n'], ['t'], ['s'], [','], [], ['s'], ['u'], ['r'], ['t'], ['o'], ['u'], ['t'], [], ['d'], ['i'], ['f'], ['f'], ['u'], ['s'], ['é'], ['s'], [], ['e'], ['n'], [], ['d'], ['i'], ['r'], ['e'], ['c'], ['t'], ['.'], [], [], [], ['L'], ['e'], [], ['q'], ['u'], ['o'], ['t'], ['i'], ['d'], ['i'], ['e'], ['n'], [], ['a'], ['f'], ['f'], ['r'], ['e'], ['u'], ['x'], [], ['d'], ['e'], [], ['c'], ['e'], ['s'], [], ['m'], ['o'], ['d'], ['é'], ['r'], ['a'], ['t'], ['e'], ['u'], ['r'], ['s'], [','], [], ['c'], ['o'], ['n'], ['t'], ['r'], ['a'], ['i'], ['n'], ['t'], ['s'], [], ['d'], ['e'], [], ['v'], ['i'], ['s'], ['i'], ['o'], ['n'], ['n'], ['e'], ['r'], [], ['d'], ['e'], ['s'], [], ['h'], ['o'], ['r'], ['r'], ['e'], ['u'], ['r'], ['s'], [], ['à'], [], ['l'], ['o'], ['n'], ['g'], ['u'], ['e'], ['u'], ['r'], [], ['d'], ['e'], [], ['j'], ['o'], ['u'], ['r'], ['n'], ['é'], ['e'], [','], [], ['m'], ['é'], ['r'], ['i'], ['t'], ['e'], ['r'], ['a'], ['i'], ['t'], [], ['p'], ['o'], ['u'], ['r'], ['t'], ['a'], ['n'], ['t'], [], ['q'], ['u'], ['’'], ['o'], ['n'], [], ['l'], ['e'], ['s'], [], ['r'], ['e'], ['m'], ['p'], ['l'], ['a'], ['c'], ['e'], [], ['v'], ['i'], ['t'], ['e'], [], ['p'], ['a'], ['r'], [], ['d'], ['e'], ['s'], [], ['m'], ['a'], ['c'], ['h'], ['i'], ['n'], ['e'], ['s'], [], ['!'], [], [], [], ['L'], ['’'], ['I'], ['A'], [], ['n'], ['e'], [], ['p'], ['e'], ['u'], ['t'], [], ['p'], ['a'], ['s'], [], ['t'], ['o'], ['u'], ['t'], [','], [], ['m'], ['a'], ['i'], ['s'], [], ['l'], ['à'], [], ['o'], ['ù'], [], ['e'], ['l'], ['l'], ['e'], [], ['p'], ['e'], ['u'], ['t'], [], ['b'], ['e'], ['a'], ['u'], ['c'], ['o'], ['u'], ['p'], [','], [], ['o'], ['n'], [], ['l'], ['a'], [], ['m'], ['a'], ['u'], ['d'], ['i'], ['t'], [','], [], ['a'], ['c'], ['c'], ['u'], ['s'], ['é'], ['e'], [], ['d'], ['e'], [], ['d'], ['é'], ['t'], ['r'], ['u'], ['i'], ['r'], ['e'], [], ['n'], ['o'], ['s'], [], ['e'], ['m'], ['p'], ['l'], ['o'], ['i'], ['s'], [','], [], ['d'], ['e'], [], ['r'], ['e'], ['m'], ['p'], ['l'], ['a'], ['c'], ['e'], ['r'], [], ['l'], ['a'], [], ['c'], ['o'], ['n'], ['v'], ['i'], ['v'], ['i'], ['a'], ['l'], ['i'], ['t'], ['é'], [], ['h'], ['u'], ['m'], ['a'], ['i'], ['n'], ['e'], ['.'], [], ['C'], ['e'], [], ['d'], ['é'], ['b'], ['a'], ['t'], [], ['r'], ['e'], ['p'], ['o'], ['s'], ['e'], [], ['s'], ['u'], ['r'], [], ['u'], ['n'], [], ['m'], ['a'], ['l'], ['e'], ['n'], ['t'], ['e'], ['n'], ['d'], ['u'], ['.'], [], [], [], ['I'], ['l'], [], ['v'], ['i'], ['e'], ['n'], ['t'], [], ['d'], ['’'], ['u'], ['n'], ['e'], [], ['d'], ['é'], ['f'], ['i'], ['n'], ['i'], ['t'], ['i'], ['o'], ['n'], [], ['d'], ['e'], [], ['l'], ['’'], ['I'], ['A'], [], ['q'], ['u'], ['i'], [], ['n'], ['’'], ['a'], [','], [], ['d'], ['a'], ['n'], ['s'], [], ['l'], ['a'], [], ['r'], ['é'], ['a'], ['l'], ['i'], ['t'], ['é'], [','], [], ['j'], ['a'], ['m'], ['a'], ['i'], ['s'], [], ['p'], ['u'], [], ['ê'], ['t'], ['r'], ['e'], [], ['m'], ['i'], ['s'], ['e'], [], ['e'], ['n'], [], ['p'], ['r'], ['a'], ['t'], ['i'], ['q'], ['u'], ['e'], [], [':'], [], ['e'], ['n'], [], ['1'], ['9'], ['5'], ['5'], [','], [], ['e'], ['l'], ['l'], ['e'], [], ['é'], ['t'], ['a'], ['i'], ['t'], [], ['v'], ['u'], ['e'], [], ['c'], ['o'], ['m'], ['m'], ['e'], [], ['l'], ['a'], [], ['c'], ['r'], ['é'], ['a'], ['t'], ['i'], ['o'], ['n'], [], ['d'], ['e'], [], ['p'], ['r'], ['o'], ['g'], ['r'], ['a'], ['m'], ['m'], ['e'], ['s'], [], ['i'], ['n'], ['f'], ['o'], ['r'], ['m'], ['a'], ['t'], ['i'], ['q'], ['u'], ['e'], ['s'], [], ['q'], ['u'], ['i'], [','], [], ['q'], ['u'], ['o'], ['i'], [], ['q'], ['u'], ['’'], ['o'], ['n'], [], ['l'], ['e'], ['u'], ['r'], [], ['c'], ['o'], ['n'], ['f'], ['i'], ['e'], [','], [], ['l'], ['e'], [], ['f'], ['e'], ['r'], ['a'], ['i'], ['e'], ['n'], ['t'], [], ['u'], ['n'], [], ['j'], ['o'], ['u'], ['r'], [], ['m'], ['i'], ['e'], ['u'], ['x'], [], ['q'], ['u'], ['e'], [], ['l'], ['e'], ['s'], [], ['h'], ['u'], ['m'], ['a'], ['i'], ['n'], ['s'], ['.'], [], ['O'], ['n'], [], ['p'], ['e'], ['n'], ['s'], ['a'], ['i'], ['t'], [], ['q'], ['u'], ['e'], [], ['t'], ['o'], ['u'], ['t'], ['e'], [], ['c'], ['a'], ['r'], ['a'], ['c'], ['t'], ['é'], ['r'], ['i'], ['s'], ['t'], ['i'], ['q'], ['u'], ['e'], [], ['d'], ['e'], [], ['l'], ['’'], ['i'], ['n'], ['t'], ['e'], ['l'], ['l'], ['i'], ['g'], ['e'], ['n'], ['c'], ['e'], [], ['h'], ['u'], ['m'], ['a'], ['i'], ['n'], ['e'], [], ['p'], ['o'], ['u'], ['r'], ['r'], ['a'], ['i'], ['t'], [], ['u'], ['n'], [], ['j'], ['o'], ['u'], ['r'], [], ['ê'], ['t'], ['r'], ['e'], [], ['s'], ['i'], [], ['p'], ['r'], ['é'], ['c'], ['i'], ['s'], ['é'], ['m'], ['e'], ['n'], ['t'], [], ['d'], ['é'], ['c'], ['r'], ['i'], ['t'], ['e'], [], ['q'], ['u'], ['’'], ['i'], ['l'], [], ['s'], ['u'], ['f'], ['f'], ['i'], ['r'], ['a'], ['i'], ['t'], [], ['d'], ['’'], ['u'], ['n'], ['e'], [], ['m'], ['a'], ['c'], ['h'], ['i'], ['n'], ['e'], [], ['p'], ['o'], ['u'], ['r'], [], ['l'], ['a'], [], ['s'], ['i'], ['m'], ['u'], ['l'], ['e'], ['r'], ['.'], [], ['C'], ['e'], [], ['n'], ['’'], ['e'], ['s'], ['t'], [], ['p'], ['a'], ['s'], [], ['v'], ['r'], ['a'], ['i'], ['.'], [], [], [], ['A'], ['n'], ['g'], ['o'], ['i'], ['s'], ['s'], ['e'], ['s'], [], ['i'], ['n'], ['f'], ['o'], ['n'], ['d'], ['é'], ['e'], ['s'], [], [], [], ['C'], ['o'], ['m'], ['m'], ['e'], [], ['l'], ['e'], [], ['d'], ['i'], ['t'], [], ['u'], ['n'], [], ['r'], ['é'], ['c'], ['e'], ['n'], ['t'], [], ['L'], ['i'], ['v'], ['r'], ['e'], [], ['b'], ['l'], ['a'], ['n'], ['c'], [], ['s'], ['u'], ['r'], [], ['l'], ['a'], [], ['q'], ['u'], ['e'], ['s'], ['t'], ['i'], ['o'], ['n'], [], ['('], ['P'], ['o'], ['u'], ['r'], ['q'], ['u'], ['o'], ['i'], [], ['i'], ['l'], [], ['n'], ['e'], [], ['f'], ['a'], ['u'], ['t'], [], ['p'], ['a'], ['s'], [], ['a'], ['v'], ['o'], ['i'], ['r'], [], ['p'], ['e'], ['u'], ['r'], [], ['d'], ['e'], [], ['l'], ['’'], ['I'], ['n'], ['t'], ['e'], ['l'], ['l'], ['i'], ['g'], ['e'], ['n'], ['c'], ['e'], [], ['a'], ['r'], ['t'], ['i'], ['\\xad'], ['f'], ['i'], ['c'], ['i'], ['e'], ['l'], ['l'], ['e'], [','], [], ['J'], ['u'], ['l'], ['i'], ['e'], ['n'], [], ['M'], ['a'], ['l'], ['d'], ['o'], ['n'], ['a'], ['t'], ['o'], [','], [], ['D'], ['e'], ['l'], ['o'], ['i'], ['t'], ['t'], ['e'], [','], [], ['m'], ['a'], ['r'], ['s'], [], ['2'], ['0'], ['1'], ['7'], [')'], [','], [], ['r'], ['i'], ['e'], ['n'], [], ['n'], ['e'], [], ['p'], ['o'], ['u'], ['r'], ['r'], ['a'], [], ['r'], ['e'], ['m'], ['p'], ['l'], ['a'], ['c'], ['e'], ['r'], [], ['u'], ['n'], [], ['h'], ['u'], ['m'], ['a'], ['i'], ['n'], [], ['d'], ['a'], ['n'], ['s'], [], ['s'], ['a'], [], ['g'], ['l'], ['o'], ['b'], ['a'], ['l'], ['i'], ['t'], ['é'], ['.'], [], [], [], ['L'], ['’'], ['I'], ['A'], [','], [], ['c'], ['’'], ['e'], ['s'], ['t'], [], ['d'], ['e'], [], ['l'], ['’'], ['a'], ['p'], ['p'], ['r'], ['e'], ['n'], ['t'], ['i'], ['s'], ['s'], ['a'], ['g'], ['e'], [], ['a'], ['u'], ['t'], ['o'], ['m'], ['a'], ['t'], ['i'], ['q'], ['u'], ['e'], [], ['d'], ['o'], ['t'], ['é'], [], ['d'], ['’'], ['u'], ['n'], [], ['p'], ['r'], ['o'], ['c'], ['e'], ['s'], ['s'], ['u'], ['s'], [], ['d'], ['’'], ['a'], ['j'], ['u'], ['s'], ['t'], ['e'], ['m'], ['e'], ['n'], ['t'], [], ['d'], ['e'], [], ['m'], ['o'], ['d'], ['è'], ['l'], ['e'], ['s'], [], ['s'], ['t'], ['a'], ['t'], ['i'], ['s'], ['t'], ['i'], ['q'], ['u'], ['e'], ['s'], [], ['à'], [], ['d'], ['e'], ['s'], [], ['m'], ['a'], ['s'], ['s'], ['e'], ['s'], [], ['d'], ['e'], [], ['d'], ['o'], ['n'], ['n'], ['é'], ['e'], ['s'], [','], [], ['e'], ['x'], ['p'], ['l'], ['i'], ['q'], ['u'], ['e'], [], ['l'], ['’'], ['a'], ['u'], ['t'], ['e'], ['u'], ['r'], ['.'], [], ['I'], ['l'], [], ['s'], ['’'], ['a'], ['g'], ['i'], ['t'], [], ['d'], ['’'], ['u'], ['n'], [], ['a'], ['p'], ['p'], ['r'], ['e'], ['n'], ['t'], ['i'], ['s'], ['s'], ['a'], ['g'], ['e'], [], ['s'], ['u'], ['r'], [], ['d'], ['e'], ['s'], [], ['p'], ['a'], ['r'], ['a'], ['m'], ['è'], ['t'], ['r'], ['e'], ['s'], [], ['p'], ['o'], ['u'], ['r'], [], ['l'], ['e'], ['s'], ['q'], ['u'], ['e'], ['l'], ['s'], [], ['u'], ['n'], ['e'], [], ['v'], ['i'], ['s'], ['i'], ['o'], ['n'], [], ['h'], ['u'], ['m'], ['a'], ['i'], ['n'], ['e'], [], ['n'], ['’'], ['e'], ['x'], ['p'], ['l'], ['i'], ['q'], ['u'], ['e'], [], ['p'], ['a'], ['s'], [], ['p'], ['o'], ['u'], ['r'], ['q'], ['u'], ['o'], ['i'], [], ['i'], ['l'], ['s'], [], ['m'], ['a'], ['r'], ['c'], ['h'], ['e'], ['n'], ['t'], [], ['s'], ['i'], [], ['b'], ['i'], ['e'], ['n'], [], ['d'], ['a'], ['n'], ['s'], [], ['u'], ['n'], [], ['c'], ['o'], ['n'], ['t'], ['e'], ['x'], ['t'], ['e'], [], ['d'], ['o'], ['n'], ['n'], ['é'], ['.'], [], [], [], ['C'], ['’'], ['e'], ['s'], ['t'], [], ['a'], ['u'], ['s'], ['s'], ['i'], [], ['c'], ['e'], [], ['q'], ['u'], ['e'], [], ['d'], ['i'], ['t'], [], ['l'], ['e'], [], ['r'], ['a'], ['p'], ['p'], ['o'], ['r'], ['t'], [], ['d'], ['e'], [], ['l'], ['’'], ['O'], ['f'], ['f'], ['i'], ['c'], ['e'], [], ['p'], ['a'], ['r'], ['l'], ['e'], ['m'], ['e'], ['n'], ['t'], ['a'], ['i'], ['r'], ['e'], [], ['d'], ['’'], ['é'], ['v'], ['a'], ['l'], ['u'], ['a'], ['t'], ['i'], ['o'], ['n'], [], ['d'], ['e'], ['s'], [], ['c'], ['h'], ['o'], ['i'], ['x'], [], ['s'], ['c'], ['i'], ['e'], ['n'], ['t'], ['i'], ['f'], ['i'], ['q'], ['u'], ['e'], ['s'], [], ['e'], ['t'], [], ['t'], ['e'], ['c'], ['h'], ['n'], ['o'], ['l'], ['o'], ['g'], ['i'], ['q'], ['u'], ['e'], ['s'], [], ['('], ['«'], [], ['P'], ['o'], ['u'], ['r'], [], ['u'], ['n'], ['e'], [], ['i'], ['n'], ['t'], ['e'], ['l'], ['l'], ['i'], ['g'], ['e'], ['n'], ['c'], ['e'], [], ['a'], ['r'], ['t'], ['i'], ['f'], ['i'], ['c'], ['i'], ['e'], ['l'], ['l'], ['e'], [], ['m'], ['a'], ['î'], ['t'], ['r'], ['i'], ['s'], ['é'], ['e'], [','], [], ['u'], ['t'], ['i'], ['l'], ['e'], [], ['e'], ['t'], [], ['d'], ['é'], ['m'], ['y'], ['s'], ['t'], ['i'], ['f'], ['i'], ['é'], ['e'], [], ['»'], [','], [], ['2'], ['9'], [], ['m'], ['a'], ['r'], ['s'], [], ['2'], ['0'], ['1'], ['7'], [')'], [','], [], ['p'], ['o'], ['u'], ['r'], [], ['q'], ['u'], ['i'], [], ['c'], ['e'], [], ['c'], ['ô'], ['t'], ['é'], [], ['«'], [], ['b'], ['o'], ['î'], ['t'], ['e'], [], ['n'], ['o'], ['i'], ['r'], ['e'], [], ['»'], [], ['e'], ['x'], ['p'], ['l'], ['i'], ['q'], ['u'], ['e'], [], ['d'], ['e'], ['s'], [], ['a'], ['n'], ['g'], ['o'], ['i'], ['s'], ['s'], ['e'], ['s'], [], ['i'], ['n'], ['f'], ['o'], ['n'], ['d'], ['é'], ['e'], ['s'], ['.'], [], ['E'], ['t'], ['h'], ['i'], ['q'], ['u'], ['e'], ['m'], ['e'], ['n'], ['t'], [','], [], ['s'], ['e'], [], ['f'], ['o'], ['n'], ['d'], ['e'], ['r'], [], ['s'], ['u'], ['r'], [], ['l'], ['’'], ['I'], ['A'], [], ['p'], ['o'], ['u'], ['r'], [], ['d'], ['e'], ['s'], [], ['t'], ['â'], ['c'], ['h'], ['e'], ['s'], [], ['c'], ['r'], ['i'], ['t'], ['i'], ['q'], ['u'], ['e'], ['s'], [], ['s'], ['a'], ['n'], ['s'], [], ['b'], ['i'], ['e'], ['n'], [], ['c'], ['o'], ['m'], ['p'], ['r'], ['e'], ['n'], ['d'], ['r'], ['e'], [], ['l'], ['e'], [], ['c'], ['o'], ['m'], ['m'], ['e'], ['n'], ['t'], ['.'], ['.'], ['.']]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each item in the french file\n",
    "tokens_french = [word_tokenize(item) for item in french]\n",
    "\n",
    "print(tokens_french)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "320fd5f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Stuning', 'even', 'for', 'the', 'non-gamer', ':', 'This', 'sound', 'track', 'was', 'beautiful', '!', 'It', 'paints', 'the', 'senery', 'in', 'your', 'mind', 'so', 'well', 'I', 'would', 'recomend', 'it', 'even', 'to', 'people', 'who', 'hate', 'vid', '.', 'game', 'music', '!', 'I', 'have', 'played', 'the', 'game', 'Chrono', 'Cross', 'but', 'out', 'of', 'all', 'of', 'the', 'games', 'I', 'have', 'ever', 'played', 'it', 'has', 'the', 'best', 'music', '!', 'It', 'backs', 'away', 'from', 'crude', 'keyboarding', 'and', 'takes', 'a', 'fresher', 'step', 'with', 'grate', 'guitars', 'and', 'soulful', 'orchestras', '.', 'It', 'would', 'impress', 'anyone', 'who', 'cares', 'to', 'listen', '!', '^_^']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize each item in the review column \n",
    "word_tokens = [word_tokenize(review) for review in reviews.review]\n",
    "\n",
    "# Print out the first item of the word_tokens list\n",
    "print(word_tokens[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6fcb225",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        87\n",
       "1       109\n",
       "2       165\n",
       "3       145\n",
       "4       109\n",
       "       ... \n",
       "9995    175\n",
       "9996    153\n",
       "9997    122\n",
       "9998     33\n",
       "9999    115\n",
       "Name: n_words, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty list to store the length of reviews\n",
    "len_tokens = []\n",
    "\n",
    "# Iterate over the word_tokens list and determine the length of each item\n",
    "for i in range(len(word_tokens)):\n",
    "     len_tokens.append(len(word_tokens[i]))\n",
    "\n",
    "# Create a new feature for the lengh of each review\n",
    "reviews['n_words'] = len_tokens\n",
    "reviews['n_words']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e41c8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fr:0.99999728129865]\n"
     ]
    }
   ],
   "source": [
    "# Import the language detection function and package\n",
    "from langdetect import detect_langs\n",
    "\n",
    "# Detect the language of the foreign string\n",
    "print(detect_langs(french))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "331020b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"L'histoire rendu était fidèle, excellent, et grande.\"\n",
      "'Excelente muy recomendable.'\n",
      "'It had a leak from day one but the return and exchange process was very quick.'\n"
     ]
    }
   ],
   "source": [
    "# Open the text file for reading\n",
    "with open('sentences.txt', 'r') as file:\n",
    "    # Read the contents of the file into a variable\n",
    "    sentences = file.read()\n",
    "\n",
    "# Print the contents of the file\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d60ae6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fr:0.5714263774480309, en:0.42857187194929086]\n"
     ]
    }
   ],
   "source": [
    "# Detect the language of the foreign string\n",
    "print(detect_langs(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "558b67e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The detected languages are:  [[en:0.8571394292751591, fr:0.142859653983222], [en:0.5714274036836346, fr:0.4285716737134673], [en:0.8571403108411642, fr:0.1428587975511281], [fr:0.5714288607432911, en:0.42857048449261836], [en:0.7142819360771533, fr:0.2857165710432299], [fr:0.7142836590558499, en:0.2857148241334628], [en:0.5714276770839963, fr:0.4285722850731491], [fr:0.7142837519781026, en:0.2857146181093787], [en:0.5714293683307263, fr:0.4285702958786709], [en:0.7142852566483823, fr:0.2857145165943707], [en:0.5714299661095953, fr:0.42856984687092337], [fr:0.5714282244065704, en:0.4285716594251519], [fr:0.5714282142335395, en:0.42857178399257756], [fr:0.5714279696474862, en:0.42857201076535795], [en:0.5714289039672809, fr:0.42857109116188674], [en:0.714285027731459, fr:0.28571460753233036], [fr:0.5714263880116018, en:0.42857089797125], [fr:0.7142835206183159, en:0.2857164503561384], [en:0.7142846850890423, fr:0.28571524315091074], [fr:0.7142867164009393, en:0.28571328346008795], [en:0.7142828712532421, fr:0.2857166442017987], [en:0.7142822741950646, fr:0.2857171390260798], [en:0.5714269299715691, fr:0.4285719954641931], [en:0.8571388339250667, fr:0.1428584782810291], [en:0.7142846073693716, fr:0.28571497678517344], [fr:0.7142846853565014, en:0.2857149086185545], [en:0.7142841686220497, fr:0.2857149836798859], [fr:0.7142815323189797, en:0.2857179256136839], [fr:0.5714275119804366, en:0.42857228662583746], [en:0.8571409786702462, fr:0.1428589971090576], [en:0.9999970516100902], [en:0.8571388737501384, fr:0.1428610733013488], [fr:0.5714276456130947, en:0.42857187308532085], [en:0.8571393783226637, fr:0.14285813207728298], [en:0.7142820060697399, fr:0.2857167854614012], [en:0.7142828417958619, fr:0.2857159137595041], [en:0.5714263601463062, fr:0.4285733735281667], [en:0.7142855392812069, fr:0.285714409625453], [en:0.7142845135157617, fr:0.28571406688840334], [en:0.7142845889085834, fr:0.2857142732351994], [en:0.5714281347816548, fr:0.4285715860844899], [en:0.8571405391181932, fr:0.1428593910823287], [en:0.857140210076427, fr:0.1428593584052364], [en:0.5714279411440939, fr:0.4285720098540412], [en:0.5714287617277423, fr:0.42857008047746636], [en:0.5714260095392885, fr:0.42857397422455984], [en:0.7142853861638393, fr:0.2857145042585918], [fr:0.8571381760305541, en:0.14286054532924233], [en:0.9999954178003176], [en:0.7142852444123581, fr:0.28571422815287617], [fr:0.5714273850803632, en:0.42857232649560534], [en:0.714282515804023, fr:0.2857163248005018], [en:0.7142839303848014, fr:0.28571486931792267], [en:0.714284805646559, fr:0.28571486755607844], [fr:0.7142827765566138, en:0.28571542134982103], [en:0.8571386317883314, fr:0.14286025164270363], [fr:0.5714286443133161, en:0.4285708441908054], [en:0.5714283524504095, fr:0.4285706704911632], [en:0.8571413649130767, fr:0.14285830420449086], [en:0.714282953290944, fr:0.2857155998867476], [fr:0.5714273410595412, en:0.42857214049421605], [fr:0.7142841492470815, en:0.2857158398828715], [fr:0.5714281565739135, en:0.42857152257013464], [en:0.571429877416578, fr:0.42857009515656014], [en:0.9999958999510996], [en:0.5714270312186457, fr:0.4285721577473617], [en:0.571428361176868, fr:0.42857078223172473], [en:0.8571404002806159, fr:0.14285822725288022], [fr:0.5714287889146314, en:0.4285712013508378], [en:0.9999962149185575], [en:0.7142841217922234, fr:0.28571467211543544], [en:0.8571402909414442, fr:0.1428591368897693], [en:0.8571396840440952, fr:0.1428579746535296], [en:0.5714296645780386, fr:0.4285698012580504], [en:0.7142838269300624, fr:0.28571522222163626], [en:0.5714267950625679, fr:0.42857257865092413], [en:0.7142852669542382, fr:0.28571453841756594], [en:0.5714270306563991, fr:0.42857141436772345], [fr:0.5714275935695775, en:0.4285717882438464], [en:0.857140000237528, fr:0.14285873347640005], [fr:0.571426518940227, en:0.428573481059329], [fr:0.5714252228892986, en:0.42857409322458345], [en:0.5714274752114081, fr:0.4285715014959812], [en:0.8571405564408233, fr:0.1428585378467851], [en:0.7142843545112002, fr:0.28571403597834394], [fr:0.8571389547849848, en:0.14285967746778253], [en:0.5714269739064891, fr:0.4285728828415146], [fr:0.7142829749196461, en:0.285715482535432], [fr:0.8571397553864977, en:0.14285872502611632], [en:0.5714269372712203, fr:0.42857268818070715], [fr:0.5714269947566307, en:0.4285718523776767], [fr:0.5714271711983973, en:0.4285724827728503], [fr:0.5714270570254179, en:0.4285729312495519], [en:0.7142832235387503, fr:0.2857150858456067], [en:0.5714271855652723, fr:0.4285727215622197], [fr:0.5714280072867786, en:0.428571076810317], [en:0.7142829389457688, fr:0.28571706070244024], [fr:0.714282710544784, en:0.28571717008153474], [en:0.5714263505832419, fr:0.4285733890846581], [en:0.7142852945332829, fr:0.2857142646476116], [fr:0.5714272199280725, en:0.42857244609991063], [en:0.5714275620168359, fr:0.428571216325512], [en:0.5714273225483303, fr:0.42857130019797707], [en:0.7142837808742274, fr:0.2857146736726469], [fr:0.5714283026155762, en:0.42856978462826356], [fr:0.5714280185289087, en:0.4285703890790757], [en:0.8571397849297893, fr:0.14286019733873837], [fr:0.5714265456203054, en:0.42857172045656045], [en:0.7142836738655489, fr:0.28571561307169835], [fr:0.5714264930071784, en:0.4285714420379258], [fr:0.7142847809084696, en:0.28571508126380074], [en:0.7142847453973987, fr:0.28571395352137235], [fr:0.5714298169067398, en:0.42856998194465157], [en:0.571426446370088, fr:0.42857277133760613], [fr:0.5714271076445908, en:0.42857209388421985], [fr:0.5714272531207955, en:0.42856992828907836], [fr:0.5714273164706455, en:0.4285714507183331], [en:0.7142836172944274, fr:0.28571491598551424], [en:0.5714283571389219, fr:0.4285705904772825], [en:0.8571396501207624, fr:0.1428602711372991], [en:0.5714275943031234, fr:0.42857151682855726], [en:0.7142833317978892, fr:0.28571584908564635], [en:0.7142840814788898, fr:0.28571555844754204], [fr:0.5714277374389325, en:0.4285719507933987], [fr:0.5714276678175663, en:0.4285718725230395], [fr:0.5714258529369267, en:0.4285741304709766], [en:0.714282226336052, fr:0.28571612450635925], [fr:0.7142823486337051, en:0.28571759705274447], [en:0.7142837968637663, fr:0.28571443168019917], [en:0.5714266291340054, fr:0.4285726500842317], [en:0.571429220348667, fr:0.4285703652531926], [en:0.8571416188037592, fr:0.14285806777082222], [en:0.9999958317206619], [en:0.8571411535860647, fr:0.14285884360236922], [en:0.8571395878358715, fr:0.14285989073835195], [fr:0.7142838672605779, en:0.2857161219734491], [en:0.7142816358571478, fr:0.28571734943244753], [en:0.7142842310999159, fr:0.2857156163374441], [fr:0.7142850334797435, en:0.2857147954141165], [fr:0.5714292918166594, en:0.4285707076610389], [fr:0.5714270335109949, en:0.4285712412601268], [fr:0.7142840524379166, en:0.28571495597987856], [en:0.5714283918223506, fr:0.42857052006109164], [en:0.7142822663736415, fr:0.2857173679418665], [en:0.5714286520637593, fr:0.4285698641308162], [en:0.714284830802307, fr:0.2857148006783743], [en:0.71428393523617, fr:0.2857154832861958], [en:0.5714295013429587, fr:0.42857043954477725], [en:0.571429673962987, fr:0.4285697178689076], [fr:0.5714269148251423, en:0.42857254031338277], [en:0.5714281657891148, fr:0.428571821201626], [en:0.7142841176410044, fr:0.2857158236897954], [fr:0.7142833307182284, en:0.28571398204455417], [en:0.7142842734144595, fr:0.2857147023178676], [en:0.7142861216445011, fr:0.2857128146362304], [fr:0.5714257427054955, en:0.42857306694678593], [en:0.7142826716994268, fr:0.2857154496661067], [fr:0.7142849563687659, en:0.28571404226284447], [fr:0.5714295960145497, en:0.42857034059942106], [fr:0.5714279503402419, en:0.4285719264138252], [en:0.7142847591370536, fr:0.2857152233936693], [fr:0.5714278766951306, en:0.4285696097987637], [en:0.5714260045584048, fr:0.4285739369386172], [fr:0.5714284892717132, en:0.4285711496918192], [fr:0.5714272750718044, en:0.4285718058712045]]\n"
     ]
    }
   ],
   "source": [
    "languages = []\n",
    "\n",
    "# Loop over the sentences in the list and detect their language\n",
    "for sentence in sentences:\n",
    "    languages.append(detect_langs(sentences))\n",
    "    \n",
    "print('The detected languages are: ', languages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0955ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# languages = [] \n",
    "\n",
    "# # Loop over the rows of the dataset and append  \n",
    "# for row in range(len(non_english_reviews)):\n",
    "#     languages.append(detect_langs(non_english_reviews.iloc[row, 1]))\n",
    "\n",
    "# # Clean the list by splitting     \n",
    "# languages = [str(lang).split(':')[0][1:] for lang in languages]\n",
    "\n",
    "# # Assign the list to a new feature \n",
    "# non_english_reviews['language'] = languages\n",
    "\n",
    "# print(non_english_reviews.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "358ebf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import libraries\n",
    "# from wordcloud import WordCloud, STOPWORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8788657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create and generate a word cloud image\n",
    "# my_cloud = WordCloud(background_color='white').generate(text_tweet)\n",
    "\n",
    "# # Display the generated wordcloud image\n",
    "# plt.imshow(my_cloud, interpolation='bilinear') \n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# # Don't forget to show the final image\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "30c5c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the list of stopwords\n",
    "# my_stop_words = STOPWORDS.update(['airline', 'airplane'])\n",
    "\n",
    "# # Create and generate a word cloud image\n",
    "# my_cloud = WordCloud(stopwords=my_stop_words).generate(text_tweet)\n",
    "\n",
    "# # Display the generated wordcloud image\n",
    "# plt.imshow(my_cloud, interpolation='bilinear') \n",
    "# plt.axis(\"off\")\n",
    "# # Don't forget to show the final image\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb477b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the stop words\n",
    "from sklearn.feature_extraction.text import CountVectorizer, ENGLISH_STOP_WORDS \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c896594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the stop words\n",
    "# my_stop_words = ENGLISH_STOP_WORDS.union(['airline', 'airlines', '@'])\n",
    "\n",
    "# # Build and fit the vectorizer\n",
    "# vect = CountVectorizer(stop_words=my_stop_words)\n",
    "# vect.fit(tweets.text)\n",
    "\n",
    "# # Create the bow representation\n",
    "# X_review = vect.transform(tweets.text)\n",
    "# # Create the data frame\n",
    "# X_df = pd.DataFrame(X_review.toarray(), columns=vect.get_feature_names.out())\n",
    "# print(X_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b145a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the stop words\n",
    "# my_stop_words = ENGLISH_STOP_WORDS.union(['airline', 'airlines', '@', 'am', 'pm'])\n",
    " \n",
    "# # Build and fit the vectorizers\n",
    "# vect1 = CountVectorizer(stop_words=my_stop_words)\n",
    "# vect2 = CountVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "# vect1.fit(tweets.text)\n",
    "# vect2.fit(tweets.negative_reason)\n",
    "\n",
    "# # Print the last 15 features from the first, and all from second vectorizer\n",
    "# print(vect1.get_feature_names.out()[-15:])\n",
    "# print(vect2.get_feature_names.out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5678973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build and fit the vectorizer\n",
    "# vect = CountVectorizer(token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b').fit(tweets)\n",
    "# vect.transform(tweets)\n",
    "# print('Length of vectorizer: ', len(vect.get_feature_names.out()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b23c9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build the first vectorizer\n",
    "# vect1 = CountVectorizer().fit(tweets.text)\n",
    "# vect1.transform(tweets.text)\n",
    "\n",
    "# # Build the second vectorizer\n",
    "# vect2 = CountVectorizer(token_pattern=r'\\b[^\\d\\W][^\\d\\W]').fit(tweets.text)\n",
    "# vect2.transform(tweets.text)\n",
    "\n",
    "# # Print out the length of each vectorizer\n",
    "# print('Length of vectorizer 1: ', len(vect1.get_feature_names()))\n",
    "# print('Length of vectorizer 2: ', len(vect2.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21c0d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the word tokenizing package\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59aa3d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokens:  ['@', 'VirginAmerica', 'What', '@', 'dhepburn', 'said', '.']\n",
      "Cleaned tokens:  ['VirginAmerica', 'What', 'dhepburn', 'said']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text column\n",
    "word_tokens = [word_tokenize(review) for review in tweets.text]\n",
    "print('Original tokens: ', word_tokens[0])\n",
    "\n",
    "# Filter out non-letter characters\n",
    "cleaned_tokens = [[word for word in item if word.isalpha()] for item in word_tokens]\n",
    "print('Cleaned tokens: ', cleaned_tokens[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44e73ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last item in alphabetic list:  ['AmericanAir', 'we', 'have', 'ppl', 'so', 'we', 'need', 'know', 'how', 'many', 'seats', 'are', 'on', 'the', 'next', 'flight', 'Plz', 'put', 'us', 'on', 'standby', 'for', 'people', 'on', 'the', 'next', 'flight']\n",
      "Last item in list of alphanumerics:  ['AmericanAir', 'we', 'have', '8', 'ppl', 'so', 'we', 'need', '2', 'know', 'how', 'many', 'seats', 'are', 'on', 'the', 'next', 'flight', 'Plz', 'put', 'us', 'on', 'standby', 'for', '4', 'people', 'on', 'the', 'next', 'flight']\n",
      "Last item in the list of digits:  ['8', '2', '4']\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists, containing the tokens from list_tweets\n",
    "tokens = [word_tokenize(item) for item in tweets.text]\n",
    "\n",
    "# Remove characters and digits , i.e. retain only letters\n",
    "letters = [[word for word in item if word.isalpha()] for item in tokens]\n",
    "# Remove characters, i.e. retain only letters and digits\n",
    "let_digits = [[word for word in item if word.isalnum()] for item in tokens]\n",
    "# Remove letters and characters, retain only digits\n",
    "digits = [[word for word in item if word.isdigit()] for item in tokens]\n",
    "\n",
    "# Print the last item in each list\n",
    "print('Last item in alphabetic list: ', letters[-1])\n",
    "print('Last item in list of alphanumerics: ', let_digits[-1])\n",
    "print('Last item in the list of digits: ', digits[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "932deb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages from nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a32e1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffédition',\n",
       " 'abonné',\n",
       " 'Dans',\n",
       " 'une',\n",
       " 'tribune',\n",
       " 'au',\n",
       " '«',\n",
       " 'Monde',\n",
       " '»',\n",
       " ',',\n",
       " 'l',\n",
       " '’',\n",
       " 'universitaire',\n",
       " 'Charles',\n",
       " 'Cuvelliez',\n",
       " 'estime',\n",
       " 'que',\n",
       " 'le',\n",
       " 'fantasme',\n",
       " 'd',\n",
       " '’',\n",
       " 'un',\n",
       " 'remplacement',\n",
       " 'de',\n",
       " 'l',\n",
       " '’',\n",
       " 'homme',\n",
       " 'par',\n",
       " 'l',\n",
       " '’',\n",
       " 'algorithme',\n",
       " 'et',\n",
       " 'le',\n",
       " 'robot',\n",
       " 'repose',\n",
       " 'sur',\n",
       " 'un',\n",
       " 'malentendu',\n",
       " '.',\n",
       " 'Le',\n",
       " 'Monde',\n",
       " '|',\n",
       " '10.05.2017',\n",
       " 'à',\n",
       " '06h44',\n",
       " '•',\n",
       " 'Mis',\n",
       " 'à',\n",
       " 'jour',\n",
       " 'le',\n",
       " '10.05.2017',\n",
       " 'à',\n",
       " '09h47',\n",
       " '|',\n",
       " 'Par',\n",
       " 'Charles',\n",
       " 'Cuvelliez',\n",
       " '(',\n",
       " 'Professeur',\n",
       " 'à',\n",
       " 'l',\n",
       " '’',\n",
       " 'Ecole',\n",
       " 'polytechnique',\n",
       " 'de',\n",
       " \"l'université\",\n",
       " 'libre',\n",
       " 'de',\n",
       " 'Bruxelles',\n",
       " ')',\n",
       " 'TRIBUNE',\n",
       " '.',\n",
       " 'L',\n",
       " '’',\n",
       " 'usage',\n",
       " 'morbide',\n",
       " ',',\n",
       " 'par',\n",
       " 'certains',\n",
       " ',',\n",
       " 'de',\n",
       " 'Facebook',\n",
       " 'Live',\n",
       " 'a',\n",
       " 'amené',\n",
       " 'son',\n",
       " 'fondateur',\n",
       " 'à',\n",
       " 'annoncer',\n",
       " 'précipitamment',\n",
       " 'le',\n",
       " 'recrutement',\n",
       " 'de',\n",
       " '3',\n",
       " '000',\n",
       " 'modérateurs',\n",
       " 'supplémentaires',\n",
       " '.',\n",
       " 'Il',\n",
       " 'est',\n",
       " 'vrai',\n",
       " 'que',\n",
       " 'l',\n",
       " '’',\n",
       " 'intelligence',\n",
       " 'artificielle',\n",
       " '(',\n",
       " 'IA',\n",
       " ')',\n",
       " 'est',\n",
       " 'bien',\n",
       " 'en',\n",
       " 'peine',\n",
       " 'de',\n",
       " 'reconnaître',\n",
       " 'des',\n",
       " 'contenus',\n",
       " 'violents',\n",
       " ',',\n",
       " 'surtout',\n",
       " 'diffusés',\n",
       " 'en',\n",
       " 'direct',\n",
       " '.',\n",
       " 'Le',\n",
       " 'quotidien',\n",
       " 'affreux',\n",
       " 'de',\n",
       " 'ces',\n",
       " 'modérateurs',\n",
       " ',',\n",
       " 'contraints',\n",
       " 'de',\n",
       " 'visionner',\n",
       " 'des',\n",
       " 'horreurs',\n",
       " 'à',\n",
       " 'longueur',\n",
       " 'de',\n",
       " 'journée',\n",
       " ',',\n",
       " 'mériterait',\n",
       " 'pourtant',\n",
       " 'qu',\n",
       " '’',\n",
       " 'on',\n",
       " 'les',\n",
       " 'remplace',\n",
       " 'vite',\n",
       " 'par',\n",
       " 'des',\n",
       " 'machines',\n",
       " '!',\n",
       " 'L',\n",
       " '’',\n",
       " 'IA',\n",
       " 'ne',\n",
       " 'peut',\n",
       " 'pas',\n",
       " 'tout',\n",
       " ',',\n",
       " 'mais',\n",
       " 'là',\n",
       " 'où',\n",
       " 'elle',\n",
       " 'peut',\n",
       " 'beaucoup',\n",
       " ',',\n",
       " 'on',\n",
       " 'la',\n",
       " 'maudit',\n",
       " ',',\n",
       " 'accusée',\n",
       " 'de',\n",
       " 'détruire',\n",
       " 'nos',\n",
       " 'emplois',\n",
       " ',',\n",
       " 'de',\n",
       " 'remplacer',\n",
       " 'la',\n",
       " 'convivialité',\n",
       " 'humaine',\n",
       " '.',\n",
       " 'Ce',\n",
       " 'débat',\n",
       " 'repose',\n",
       " 'sur',\n",
       " 'un',\n",
       " 'malentendu',\n",
       " '.',\n",
       " 'Il',\n",
       " 'vient',\n",
       " 'd',\n",
       " '’',\n",
       " 'une',\n",
       " 'définition',\n",
       " 'de',\n",
       " 'l',\n",
       " '’',\n",
       " 'IA',\n",
       " 'qui',\n",
       " 'n',\n",
       " '’',\n",
       " 'a',\n",
       " ',',\n",
       " 'dans',\n",
       " 'la',\n",
       " 'réalité',\n",
       " ',',\n",
       " 'jamais',\n",
       " 'pu',\n",
       " 'être',\n",
       " 'mise',\n",
       " 'en',\n",
       " 'pratique',\n",
       " ':',\n",
       " 'en',\n",
       " '1955',\n",
       " ',',\n",
       " 'elle',\n",
       " 'était',\n",
       " 'vue',\n",
       " 'comme',\n",
       " 'la',\n",
       " 'création',\n",
       " 'de',\n",
       " 'programmes',\n",
       " 'informatiques',\n",
       " 'qui',\n",
       " ',',\n",
       " 'quoi',\n",
       " 'qu',\n",
       " '’',\n",
       " 'on',\n",
       " 'leur',\n",
       " 'confie',\n",
       " ',',\n",
       " 'le',\n",
       " 'feraient',\n",
       " 'un',\n",
       " 'jour',\n",
       " 'mieux',\n",
       " 'que',\n",
       " 'les',\n",
       " 'humains',\n",
       " '.',\n",
       " 'On',\n",
       " 'pensait',\n",
       " 'que',\n",
       " 'toute',\n",
       " 'caractéristique',\n",
       " 'de',\n",
       " 'l',\n",
       " '’',\n",
       " 'intelligence',\n",
       " 'humaine',\n",
       " 'pourrait',\n",
       " 'un',\n",
       " 'jour',\n",
       " 'être',\n",
       " 'si',\n",
       " 'précisément',\n",
       " 'décrite',\n",
       " 'qu',\n",
       " '’',\n",
       " 'il',\n",
       " 'suffirait',\n",
       " 'd',\n",
       " '’',\n",
       " 'une',\n",
       " 'machine',\n",
       " 'pour',\n",
       " 'la',\n",
       " 'simuler',\n",
       " '.',\n",
       " 'Ce',\n",
       " 'n',\n",
       " '’',\n",
       " 'est',\n",
       " 'pas',\n",
       " 'vrai',\n",
       " '.',\n",
       " 'Angoisses',\n",
       " 'infondées',\n",
       " 'Comme',\n",
       " 'le',\n",
       " 'dit',\n",
       " 'un',\n",
       " 'récent',\n",
       " 'Livre',\n",
       " 'blanc',\n",
       " 'sur',\n",
       " 'la',\n",
       " 'question',\n",
       " '(',\n",
       " 'Pourquoi',\n",
       " 'il',\n",
       " 'ne',\n",
       " 'faut',\n",
       " 'pas',\n",
       " 'avoir',\n",
       " 'peur',\n",
       " 'de',\n",
       " 'l',\n",
       " '’',\n",
       " 'Intelligence',\n",
       " 'arti\\xadficielle',\n",
       " ',',\n",
       " 'Julien',\n",
       " 'Maldonato',\n",
       " ',',\n",
       " 'Deloitte',\n",
       " ',',\n",
       " 'mars',\n",
       " '2017',\n",
       " ')',\n",
       " ',',\n",
       " 'rien',\n",
       " 'ne',\n",
       " 'pourra',\n",
       " 'remplacer',\n",
       " 'un',\n",
       " 'humain',\n",
       " 'dans',\n",
       " 'sa',\n",
       " 'globalité',\n",
       " '.',\n",
       " 'L',\n",
       " '’',\n",
       " 'IA',\n",
       " ',',\n",
       " 'c',\n",
       " '’',\n",
       " 'est',\n",
       " 'de',\n",
       " 'l',\n",
       " '’',\n",
       " 'apprentissage',\n",
       " 'automatique',\n",
       " 'doté',\n",
       " 'd',\n",
       " '’',\n",
       " 'un',\n",
       " 'processus',\n",
       " 'd',\n",
       " '’',\n",
       " 'ajustement',\n",
       " 'de',\n",
       " 'modèles',\n",
       " 'statistiques',\n",
       " 'à',\n",
       " 'des',\n",
       " 'masses',\n",
       " 'de',\n",
       " 'données',\n",
       " ',',\n",
       " 'explique',\n",
       " 'l',\n",
       " '’',\n",
       " 'auteur',\n",
       " '.',\n",
       " 'Il',\n",
       " 's',\n",
       " '’',\n",
       " 'agit',\n",
       " 'd',\n",
       " '’',\n",
       " 'un',\n",
       " 'apprentissage',\n",
       " 'sur',\n",
       " 'des',\n",
       " 'paramètres',\n",
       " 'pour',\n",
       " 'lesquels',\n",
       " 'une',\n",
       " 'vision',\n",
       " 'humaine',\n",
       " 'n',\n",
       " '’',\n",
       " 'explique',\n",
       " 'pas',\n",
       " 'pourquoi',\n",
       " 'ils',\n",
       " 'marchent',\n",
       " 'si',\n",
       " 'bien',\n",
       " 'dans',\n",
       " 'un',\n",
       " 'contexte',\n",
       " 'donné',\n",
       " '.',\n",
       " 'C',\n",
       " '’',\n",
       " 'est',\n",
       " 'aussi',\n",
       " 'ce',\n",
       " 'que',\n",
       " 'dit',\n",
       " 'le',\n",
       " 'rapport',\n",
       " 'de',\n",
       " 'l',\n",
       " '’',\n",
       " 'Office',\n",
       " 'parlementaire',\n",
       " 'd',\n",
       " '’',\n",
       " 'évaluation',\n",
       " 'des',\n",
       " 'choix',\n",
       " 'scientifiques',\n",
       " 'et',\n",
       " 'technologiques',\n",
       " '(',\n",
       " '«',\n",
       " 'Pour',\n",
       " 'une',\n",
       " 'intelligence',\n",
       " 'artificielle',\n",
       " 'maîtrisée',\n",
       " ',',\n",
       " 'utile',\n",
       " 'et',\n",
       " 'démystifiée',\n",
       " '»',\n",
       " ',',\n",
       " '29',\n",
       " 'mars',\n",
       " '2017',\n",
       " ')',\n",
       " ',',\n",
       " 'pour',\n",
       " 'qui',\n",
       " 'ce',\n",
       " 'côté',\n",
       " '«',\n",
       " 'boîte',\n",
       " 'noire',\n",
       " '»',\n",
       " 'explique',\n",
       " 'des',\n",
       " 'angoisses',\n",
       " 'infondées',\n",
       " '.',\n",
       " 'Ethiquement',\n",
       " ',',\n",
       " 'se',\n",
       " 'fonder',\n",
       " 'sur',\n",
       " 'l',\n",
       " '’',\n",
       " 'IA',\n",
       " 'pour',\n",
       " 'des',\n",
       " 'tâches',\n",
       " 'critiques',\n",
       " 'sans',\n",
       " 'bien',\n",
       " 'comprendre',\n",
       " 'le',\n",
       " 'comment',\n",
       " '...']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter = PorterStemmer()\n",
    "WNlemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Tokenize the GoT string\n",
    "tokens = word_tokenize(french) \n",
    "tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5f91850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5c9dfce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for stemming in seconds:  0.0023376941680908203\n",
      "Stemmed tokens:  ['\\ufeffédition', 'abonné', 'dan', 'une', 'tribun', 'au', '«', 'mond', '»', ',', 'l', '’', 'universitair', 'charl', 'cuvelliez', 'estim', 'que', 'le', 'fantasm', 'd', '’', 'un', 'remplac', 'de', 'l', '’', 'homm', 'par', 'l', '’', 'algorithm', 'et', 'le', 'robot', 'repos', 'sur', 'un', 'malentendu', '.', 'le', 'mond', '|', '10.05.2017', 'à', '06h44', '•', 'mi', 'à', 'jour', 'le', '10.05.2017', 'à', '09h47', '|', 'par', 'charl', 'cuvelliez', '(', 'professeur', 'à', 'l', '’', 'ecol', 'polytechniqu', 'de', \"l'université\", 'libr', 'de', 'bruxel', ')', 'tribun', '.', 'l', '’', 'usag', 'morbid', ',', 'par', 'certain', ',', 'de', 'facebook', 'live', 'a', 'amené', 'son', 'fondateur', 'à', 'annonc', 'précipitam', 'le', 'recrut', 'de', '3', '000', 'modérateur', 'supplémentair', '.', 'il', 'est', 'vrai', 'que', 'l', '’', 'intellig', 'artificiel', '(', 'ia', ')', 'est', 'bien', 'en', 'pein', 'de', 'reconnaîtr', 'de', 'contenu', 'violent', ',', 'surtout', 'diffusé', 'en', 'direct', '.', 'le', 'quotidien', 'affreux', 'de', 'ce', 'modérateur', ',', 'contraint', 'de', 'visionn', 'de', 'horreur', 'à', 'longueur', 'de', 'journé', ',', 'mériterait', 'pourtant', 'qu', '’', 'on', 'le', 'remplac', 'vite', 'par', 'de', 'machin', '!', 'l', '’', 'ia', 'ne', 'peut', 'pa', 'tout', ',', 'mai', 'là', 'où', 'ell', 'peut', 'beaucoup', ',', 'on', 'la', 'maudit', ',', 'accusé', 'de', 'détruir', 'no', 'emploi', ',', 'de', 'remplac', 'la', 'convivialité', 'humain', '.', 'ce', 'débat', 'repos', 'sur', 'un', 'malentendu', '.', 'il', 'vient', 'd', '’', 'une', 'définit', 'de', 'l', '’', 'ia', 'qui', 'n', '’', 'a', ',', 'dan', 'la', 'réalité', ',', 'jamai', 'pu', 'être', 'mise', 'en', 'pratiqu', ':', 'en', '1955', ',', 'ell', 'était', 'vue', 'comm', 'la', 'création', 'de', 'programm', 'informatiqu', 'qui', ',', 'quoi', 'qu', '’', 'on', 'leur', 'confi', ',', 'le', 'feraient', 'un', 'jour', 'mieux', 'que', 'le', 'humain', '.', 'on', 'pensait', 'que', 'tout', 'caractéristiqu', 'de', 'l', '’', 'intellig', 'humain', 'pourrait', 'un', 'jour', 'être', 'si', 'précisément', 'décrite', 'qu', '’', 'il', 'suffirait', 'd', '’', 'une', 'machin', 'pour', 'la', 'simul', '.', 'ce', 'n', '’', 'est', 'pa', 'vrai', '.', 'angoiss', 'infondé', 'comm', 'le', 'dit', 'un', 'récent', 'livr', 'blanc', 'sur', 'la', 'question', '(', 'pourquoi', 'il', 'ne', 'faut', 'pa', 'avoir', 'peur', 'de', 'l', '’', 'intellig', 'arti\\xadficiel', ',', 'julien', 'maldonato', ',', 'deloitt', ',', 'mar', '2017', ')', ',', 'rien', 'ne', 'pourra', 'remplac', 'un', 'humain', 'dan', 'sa', 'globalité', '.', 'l', '’', 'ia', ',', 'c', '’', 'est', 'de', 'l', '’', 'apprentissag', 'automatiqu', 'doté', 'd', '’', 'un', 'processu', 'd', '’', 'ajust', 'de', 'modèl', 'statistiqu', 'à', 'de', 'mass', 'de', 'donné', ',', 'expliqu', 'l', '’', 'auteur', '.', 'il', 's', '’', 'agit', 'd', '’', 'un', 'apprentissag', 'sur', 'de', 'paramètr', 'pour', 'lesquel', 'une', 'vision', 'humain', 'n', '’', 'expliqu', 'pa', 'pourquoi', 'il', 'marchent', 'si', 'bien', 'dan', 'un', 'context', 'donné', '.', 'c', '’', 'est', 'aussi', 'ce', 'que', 'dit', 'le', 'rapport', 'de', 'l', '’', 'offic', 'parlementair', 'd', '’', 'évaluat', 'de', 'choix', 'scientifiqu', 'et', 'technologiqu', '(', '«', 'pour', 'une', 'intellig', 'artificiel', 'maîtrisé', ',', 'util', 'et', 'démystifié', '»', ',', '29', 'mar', '2017', ')', ',', 'pour', 'qui', 'ce', 'côté', '«', 'boît', 'noir', '»', 'expliqu', 'de', 'angoiss', 'infondé', '.', 'ethiqu', ',', 'se', 'fonder', 'sur', 'l', '’', 'ia', 'pour', 'de', 'tâche', 'critiqu', 'san', 'bien', 'comprendr', 'le', 'comment', '...']\n"
     ]
    }
   ],
   "source": [
    "# Log the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Build a stemmed list\n",
    "stemmed_tokens = [porter.stem(token) for token in tokens]\n",
    "\n",
    "# Log the end time\n",
    "end_time = time.time()\n",
    "\n",
    "print('Time taken for stemming in seconds: ', end_time - start_time)\n",
    "print('Stemmed tokens: ', stemmed_tokens) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "580f39d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for lemmatizing in seconds:  0.5697731971740723\n",
      "Lemmatized tokens:  ['\\ufeffédition', 'abonné', 'Dans', 'une', 'tribune', 'au', '«', 'Monde', '»', ',', 'l', '’', 'universitaire', 'Charles', 'Cuvelliez', 'estime', 'que', 'le', 'fantasme', 'd', '’', 'un', 'remplacement', 'de', 'l', '’', 'homme', 'par', 'l', '’', 'algorithme', 'et', 'le', 'robot', 'repose', 'sur', 'un', 'malentendu', '.', 'Le', 'Monde', '|', '10.05.2017', 'à', '06h44', '•', 'Mis', 'à', 'jour', 'le', '10.05.2017', 'à', '09h47', '|', 'Par', 'Charles', 'Cuvelliez', '(', 'Professeur', 'à', 'l', '’', 'Ecole', 'polytechnique', 'de', \"l'université\", 'libre', 'de', 'Bruxelles', ')', 'TRIBUNE', '.', 'L', '’', 'usage', 'morbide', ',', 'par', 'certains', ',', 'de', 'Facebook', 'Live', 'a', 'amené', 'son', 'fondateur', 'à', 'annoncer', 'précipitamment', 'le', 'recrutement', 'de', '3', '000', 'modérateurs', 'supplémentaires', '.', 'Il', 'est', 'vrai', 'que', 'l', '’', 'intelligence', 'artificielle', '(', 'IA', ')', 'est', 'bien', 'en', 'peine', 'de', 'reconnaître', 'de', 'contenus', 'violents', ',', 'surtout', 'diffusés', 'en', 'direct', '.', 'Le', 'quotidien', 'affreux', 'de', 'ce', 'modérateurs', ',', 'contraints', 'de', 'visionner', 'de', 'horreurs', 'à', 'longueur', 'de', 'journée', ',', 'mériterait', 'pourtant', 'qu', '’', 'on', 'le', 'remplace', 'vite', 'par', 'de', 'machine', '!', 'L', '’', 'IA', 'ne', 'peut', 'pa', 'tout', ',', 'mais', 'là', 'où', 'elle', 'peut', 'beaucoup', ',', 'on', 'la', 'maudit', ',', 'accusée', 'de', 'détruire', 'no', 'emplois', ',', 'de', 'remplacer', 'la', 'convivialité', 'humaine', '.', 'Ce', 'débat', 'repose', 'sur', 'un', 'malentendu', '.', 'Il', 'vient', 'd', '’', 'une', 'définition', 'de', 'l', '’', 'IA', 'qui', 'n', '’', 'a', ',', 'dans', 'la', 'réalité', ',', 'jamais', 'pu', 'être', 'mise', 'en', 'pratique', ':', 'en', '1955', ',', 'elle', 'était', 'vue', 'comme', 'la', 'création', 'de', 'programme', 'informatiques', 'qui', ',', 'quoi', 'qu', '’', 'on', 'leur', 'confie', ',', 'le', 'feraient', 'un', 'jour', 'mieux', 'que', 'le', 'humains', '.', 'On', 'pensait', 'que', 'toute', 'caractéristique', 'de', 'l', '’', 'intelligence', 'humaine', 'pourrait', 'un', 'jour', 'être', 'si', 'précisément', 'décrite', 'qu', '’', 'il', 'suffirait', 'd', '’', 'une', 'machine', 'pour', 'la', 'simuler', '.', 'Ce', 'n', '’', 'est', 'pa', 'vrai', '.', 'Angoisses', 'infondées', 'Comme', 'le', 'dit', 'un', 'récent', 'Livre', 'blanc', 'sur', 'la', 'question', '(', 'Pourquoi', 'il', 'ne', 'faut', 'pa', 'avoir', 'peur', 'de', 'l', '’', 'Intelligence', 'arti\\xadficielle', ',', 'Julien', 'Maldonato', ',', 'Deloitte', ',', 'mar', '2017', ')', ',', 'rien', 'ne', 'pourra', 'remplacer', 'un', 'humain', 'dans', 'sa', 'globalité', '.', 'L', '’', 'IA', ',', 'c', '’', 'est', 'de', 'l', '’', 'apprentissage', 'automatique', 'doté', 'd', '’', 'un', 'processus', 'd', '’', 'ajustement', 'de', 'modèles', 'statistiques', 'à', 'de', 'mass', 'de', 'données', ',', 'explique', 'l', '’', 'auteur', '.', 'Il', 's', '’', 'agit', 'd', '’', 'un', 'apprentissage', 'sur', 'de', 'paramètres', 'pour', 'lesquels', 'une', 'vision', 'humaine', 'n', '’', 'explique', 'pa', 'pourquoi', 'il', 'marchent', 'si', 'bien', 'dans', 'un', 'contexte', 'donné', '.', 'C', '’', 'est', 'aussi', 'ce', 'que', 'dit', 'le', 'rapport', 'de', 'l', '’', 'Office', 'parlementaire', 'd', '’', 'évaluation', 'de', 'choix', 'scientifiques', 'et', 'technologiques', '(', '«', 'Pour', 'une', 'intelligence', 'artificielle', 'maîtrisée', ',', 'utile', 'et', 'démystifiée', '»', ',', '29', 'mar', '2017', ')', ',', 'pour', 'qui', 'ce', 'côté', '«', 'boîte', 'noire', '»', 'explique', 'de', 'angoisses', 'infondées', '.', 'Ethiquement', ',', 'se', 'fonder', 'sur', 'l', '’', 'IA', 'pour', 'de', 'tâches', 'critique', 'sans', 'bien', 'comprendre', 'le', 'comment', '...']\n"
     ]
    }
   ],
   "source": [
    "# Log the start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Build a lemmatized list\n",
    "lem_tokens = [WNlemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "# Log the end time\n",
    "end_time = time.time()\n",
    "\n",
    "print('Time taken for lemmatizing in seconds: ', end_time - start_time)\n",
    "print('Lemmatized tokens: ', lem_tokens) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "142b6371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the language detection package\n",
    "import langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70fcb3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the language detection package\n",
    "# import langdetect\n",
    "\n",
    "# # Loop over the rows of the dataset and append  \n",
    "# languages = [] \n",
    "# for i in range(len(non_english_reviews)):\n",
    "#     languages.append(langdetect.detect_langs(non_english_reviews.iloc[i, 1]))\n",
    "\n",
    "# # Clean the list by splitting     \n",
    "# languages = [str(lang).split(':')[0][1:] for lang in languages]\n",
    "# # Assign the list to a new feature \n",
    "# non_english_reviews['language'] = languages\n",
    "\n",
    "# # Select the Spanish ones\n",
    "# filtered_reviews = non_english_reviews[non_english_reviews.language == 'es']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a15aa483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "829fde87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stune', 'even', 'for', 'the', 'non-gam', ':', 'this', 'sound', 'track', 'was', 'beauti', '!', 'it', 'paint', 'the', 'seneri', 'in', 'your', 'mind', 'so', 'well', 'i', 'would', 'recomend', 'it', 'even', 'to', 'peopl', 'who', 'hate', 'vid', '.', 'game', 'music', '!', 'i', 'have', 'play', 'the', 'game', 'chrono', 'cross', 'but', 'out', 'of', 'all', 'of', 'the', 'game', 'i', 'have', 'ever', 'play', 'it', 'has', 'the', 'best', 'music', '!', 'it', 'back', 'away', 'from', 'crude', 'keyboard', 'and', 'take', 'a', 'fresher', 'step', 'with', 'grate', 'guitar', 'and', 'soul', 'orchestra', '.', 'it', 'would', 'impress', 'anyon', 'who', 'care', 'to', 'listen', '!', '^_^']\n"
     ]
    }
   ],
   "source": [
    "# Import the English SnowballStemmer\n",
    "EnglishStemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Create a list of tokens\n",
    "tokens = [word_tokenize(review) for review in reviews.review] \n",
    "\n",
    "# Stem the list of tokens\n",
    "stemmed_tokens = [[EnglishStemmer.stem(word) for word in token] for token in tokens]\n",
    "\n",
    "# Print the first item of the stemmed tokenss\n",
    "print(stemmed_tokens[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82624985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the function to perform stemming\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a3d21ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['tweet_id'], ['airline_senti'], ['airline_sentiment_confid'], ['negativereason'], ['negativereason_confid'], ['airlin'], ['airline_sentiment_gold'], ['name'], ['negativereason_gold'], ['retweet_count'], ['text'], ['tweet_coord'], ['tweet_creat'], ['tweet_loc'], ['user_timezon']]\n"
     ]
    }
   ],
   "source": [
    "# Call the stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "\n",
    "# Transform the array of tweets to tokens\n",
    "tokens = [word_tokenize(tweet) for tweet in tweets]\n",
    "\n",
    "# Stem the list of tokens\n",
    "stemmed_tokens = [[porter.stem(word) for word in tweet] for tweet in tokens] \n",
    "\n",
    "# Print the elements in the list\n",
    "print(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a680ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required function\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b34b1775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4472136  0.4472136  0.4472136  0.         0.4472136  0.\n",
      "  0.4472136  0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.30151134 0.         0.30151134\n",
      "  0.         0.30151134 0.30151134 0.30151134 0.30151134 0.60302269\n",
      "  0.30151134]]\n"
     ]
    }
   ],
   "source": [
    "annak = ['Happy families are all alike;', 'every unhappy family is unhappy in its own way']\n",
    "\n",
    "# Call the vectorizer and fit it\n",
    "anna_vect = TfidfVectorizer().fit(annak)\n",
    "\n",
    "# Create the tfidf representation\n",
    "anna_tfidf = anna_vect.transform(annak)\n",
    "\n",
    "# Print the result \n",
    "print(anna_tfidf.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "432277d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required vectorizer package and stop words list\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6104dcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the vectorizer and specify the arguments\n",
    "# my_pattern = r'\\b[^\\d\\W][^\\d\\W]+\\b'\n",
    "# vect = TfidfVectorizer(ngram_range=(1,2), max_features=100, token_pattern=my_pattern, stop_words=ENGLISH_STOP_WORDS).fit(tweets.text)\n",
    "\n",
    "# # Transform the vectorizer\n",
    "# X_txt = vect.transform(tweets.text)\n",
    " \n",
    "# # Transform to a data frame and specify the column names\n",
    "# X=pd.DataFrame(X_txt.toarray(), columns=vect.get_feature_names())\n",
    "# print('Top 5 rows of the DataFrame: ', X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c5365f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec70a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Build a BOW and tfidf vectorizers from the review column and with max of 100 features\n",
    "# vect1 = CountVectorizer(max_features=100).fit(reviews.review)\n",
    "# vect2 = TfidfVectorizer(max_features=100).fit(reviews.review)\n",
    "\n",
    "# # Transform the vectorizers\n",
    "# X1 = vect1.transform(reviews.review)\n",
    "# X2 = vect2.transform(reviews.review)\n",
    "\n",
    "# # Create DataFrames from the vectorizers\n",
    "# X_df1 = pd.DataFrame(X1.toarray(), columns=vect1.get_feature_names.out())\n",
    "# X_df2 = pd.DataFrame(X2.toarray(), columns=vect2.get_feature_names.out())\n",
    "# print('Top 5 rows, using BOW: \\n', X_df1.head())\n",
    "# print('Top 5 rows using tfidf: \\n', X_df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a5fd71",
   "metadata": {},
   "source": [
    "## Predict the Sentiment of a Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69f77b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7b40ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 12:01:01 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:46 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:15 -0800</td>\n",
       "      <td>Nigeria,lagos</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.6659</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:59:02 -0800</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 11:58:51 -0800</td>\n",
       "      <td>dallas, TX</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513           neutral                        1.0000   \n",
       "1      570301130888122368          positive                        0.3486   \n",
       "2      570301083672813571           neutral                        0.6837   \n",
       "3      570301031407624196          negative                        1.0000   \n",
       "4      570300817074462722          negative                        1.0000   \n",
       "...                   ...               ...                           ...   \n",
       "14635  569587686496825344          positive                        0.3487   \n",
       "14636  569587371693355008          negative                        1.0000   \n",
       "14637  569587242672398336           neutral                        1.0000   \n",
       "14638  569587188687634433          negative                        1.0000   \n",
       "14639  569587140490866689           neutral                        0.6771   \n",
       "\n",
       "               negativereason  negativereason_confidence         airline  \\\n",
       "0                         NaN                        NaN  Virgin America   \n",
       "1                         NaN                     0.0000  Virgin America   \n",
       "2                         NaN                        NaN  Virgin America   \n",
       "3                  Bad Flight                     0.7033  Virgin America   \n",
       "4                  Can't Tell                     1.0000  Virgin America   \n",
       "...                       ...                        ...             ...   \n",
       "14635                     NaN                     0.0000        American   \n",
       "14636  Customer Service Issue                     1.0000        American   \n",
       "14637                     NaN                        NaN        American   \n",
       "14638  Customer Service Issue                     0.6659        American   \n",
       "14639                     NaN                     0.0000        American   \n",
       "\n",
       "      airline_sentiment_gold             name negativereason_gold  \\\n",
       "0                        NaN          cairdin                 NaN   \n",
       "1                        NaN         jnardino                 NaN   \n",
       "2                        NaN       yvonnalynn                 NaN   \n",
       "3                        NaN         jnardino                 NaN   \n",
       "4                        NaN         jnardino                 NaN   \n",
       "...                      ...              ...                 ...   \n",
       "14635                    NaN  KristenReenders                 NaN   \n",
       "14636                    NaN         itsropes                 NaN   \n",
       "14637                    NaN         sanyabun                 NaN   \n",
       "14638                    NaN       SraJackson                 NaN   \n",
       "14639                    NaN        daviddtwu                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0                @VirginAmerica What @dhepburn said.   \n",
       "1                  0  @VirginAmerica plus you've added commercials t...   \n",
       "2                  0  @VirginAmerica I didn't today... Must mean I n...   \n",
       "3                  0  @VirginAmerica it's really aggressive to blast...   \n",
       "4                  0  @VirginAmerica and it's a really big bad thing...   \n",
       "...              ...                                                ...   \n",
       "14635              0  @AmericanAir thank you we got on a different f...   \n",
       "14636              0  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637              0  @AmericanAir Please bring American Airlines to...   \n",
       "14638              0  @AmericanAir you have my money, you change my ...   \n",
       "14639              0  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "      tweet_coord              tweet_created tweet_location  \\\n",
       "0             NaN  2015-02-24 11:35:52 -0800            NaN   \n",
       "1             NaN  2015-02-24 11:15:59 -0800            NaN   \n",
       "2             NaN  2015-02-24 11:15:48 -0800      Lets Play   \n",
       "3             NaN  2015-02-24 11:15:36 -0800            NaN   \n",
       "4             NaN  2015-02-24 11:14:45 -0800            NaN   \n",
       "...           ...                        ...            ...   \n",
       "14635         NaN  2015-02-22 12:01:01 -0800            NaN   \n",
       "14636         NaN  2015-02-22 11:59:46 -0800          Texas   \n",
       "14637         NaN  2015-02-22 11:59:15 -0800  Nigeria,lagos   \n",
       "14638         NaN  2015-02-22 11:59:02 -0800     New Jersey   \n",
       "14639         NaN  2015-02-22 11:58:51 -0800     dallas, TX   \n",
       "\n",
       "                    user_timezone  \n",
       "0      Eastern Time (US & Canada)  \n",
       "1      Pacific Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3      Pacific Time (US & Canada)  \n",
       "4      Pacific Time (US & Canada)  \n",
       "...                           ...  \n",
       "14635                         NaN  \n",
       "14636                         NaN  \n",
       "14637                         NaN  \n",
       "14638  Eastern Time (US & Canada)  \n",
       "14639                         NaN  \n",
       "\n",
       "[14640 rows x 15 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('Tweets.csv')\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b7df18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>negativereason_Bad Flight</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_location_✈ Check ☟ out ☟ my blog ☟</th>\n",
       "      <th>tweet_location_✈️ Birmingham ✈️ Brooklyn ✈️</th>\n",
       "      <th>tweet_location_✈️FL/NJ/NYC</th>\n",
       "      <th>tweet_location_✈️✈️</th>\n",
       "      <th>tweet_location_✖️ || 4/5 || ✖️</th>\n",
       "      <th>tweet_location_✡ Los Angeles ✡</th>\n",
       "      <th>tweet_location_✨</th>\n",
       "      <th>tweet_location_❤</th>\n",
       "      <th>tweet_location_サマセット、ニュージャージー州</th>\n",
       "      <th>tweet_location_명동서식 37.56638,126.984994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>569587686496825344</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>American</td>\n",
       "      <td>KristenReenders</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>2015-02-22 12:01:01 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>569587371693355008</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>itsropes</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>2015-02-22 11:59:46 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>569587242672398336</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>sanyabun</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>2015-02-22 11:59:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>569587188687634433</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>American</td>\n",
       "      <td>SraJackson</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>2015-02-22 11:59:02 -0800</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>569587140490866689</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>American</td>\n",
       "      <td>daviddtwu</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>2015-02-22 11:58:51 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 5358 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0      570306133677760513           neutral                        1.0000   \n",
       "1      570301130888122368          positive                        0.3486   \n",
       "2      570301083672813571           neutral                        0.6837   \n",
       "3      570301031407624196          negative                        1.0000   \n",
       "4      570300817074462722          negative                        1.0000   \n",
       "...                   ...               ...                           ...   \n",
       "14635  569587686496825344          positive                        0.3487   \n",
       "14636  569587371693355008          negative                        1.0000   \n",
       "14637  569587242672398336           neutral                        1.0000   \n",
       "14638  569587188687634433          negative                        1.0000   \n",
       "14639  569587140490866689           neutral                        0.6771   \n",
       "\n",
       "              airline             name  retweet_count  \\\n",
       "0      Virgin America          cairdin              0   \n",
       "1      Virgin America         jnardino              0   \n",
       "2      Virgin America       yvonnalynn              0   \n",
       "3      Virgin America         jnardino              0   \n",
       "4      Virgin America         jnardino              0   \n",
       "...               ...              ...            ...   \n",
       "14635        American  KristenReenders              0   \n",
       "14636        American         itsropes              0   \n",
       "14637        American         sanyabun              0   \n",
       "14638        American       SraJackson              0   \n",
       "14639        American        daviddtwu              0   \n",
       "\n",
       "                                                    text  \\\n",
       "0                    @VirginAmerica What @dhepburn said.   \n",
       "1      @VirginAmerica plus you've added commercials t...   \n",
       "2      @VirginAmerica I didn't today... Must mean I n...   \n",
       "3      @VirginAmerica it's really aggressive to blast...   \n",
       "4      @VirginAmerica and it's a really big bad thing...   \n",
       "...                                                  ...   \n",
       "14635  @AmericanAir thank you we got on a different f...   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...   \n",
       "14637  @AmericanAir Please bring American Airlines to...   \n",
       "14638  @AmericanAir you have my money, you change my ...   \n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...   \n",
       "\n",
       "                   tweet_created               user_timezone  \\\n",
       "0      2015-02-24 11:35:52 -0800  Eastern Time (US & Canada)   \n",
       "1      2015-02-24 11:15:59 -0800  Pacific Time (US & Canada)   \n",
       "2      2015-02-24 11:15:48 -0800  Central Time (US & Canada)   \n",
       "3      2015-02-24 11:15:36 -0800  Pacific Time (US & Canada)   \n",
       "4      2015-02-24 11:14:45 -0800  Pacific Time (US & Canada)   \n",
       "...                          ...                         ...   \n",
       "14635  2015-02-22 12:01:01 -0800                         NaN   \n",
       "14636  2015-02-22 11:59:46 -0800                         NaN   \n",
       "14637  2015-02-22 11:59:15 -0800                         NaN   \n",
       "14638  2015-02-22 11:59:02 -0800  Eastern Time (US & Canada)   \n",
       "14639  2015-02-22 11:58:51 -0800                         NaN   \n",
       "\n",
       "       negativereason_Bad Flight  ...  \\\n",
       "0                              0  ...   \n",
       "1                              0  ...   \n",
       "2                              0  ...   \n",
       "3                              1  ...   \n",
       "4                              0  ...   \n",
       "...                          ...  ...   \n",
       "14635                          0  ...   \n",
       "14636                          0  ...   \n",
       "14637                          0  ...   \n",
       "14638                          0  ...   \n",
       "14639                          0  ...   \n",
       "\n",
       "       tweet_location_✈ Check ☟ out ☟ my blog ☟  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "14635                                         0   \n",
       "14636                                         0   \n",
       "14637                                         0   \n",
       "14638                                         0   \n",
       "14639                                         0   \n",
       "\n",
       "       tweet_location_✈️ Birmingham ✈️ Brooklyn ✈️  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "14635                                            0   \n",
       "14636                                            0   \n",
       "14637                                            0   \n",
       "14638                                            0   \n",
       "14639                                            0   \n",
       "\n",
       "       tweet_location_✈️FL/NJ/NYC  tweet_location_✈️✈️  \\\n",
       "0                               0                    0   \n",
       "1                               0                    0   \n",
       "2                               0                    0   \n",
       "3                               0                    0   \n",
       "4                               0                    0   \n",
       "...                           ...                  ...   \n",
       "14635                           0                    0   \n",
       "14636                           0                    0   \n",
       "14637                           0                    0   \n",
       "14638                           0                    0   \n",
       "14639                           0                    0   \n",
       "\n",
       "       tweet_location_✖️ || 4/5 || ✖️  tweet_location_✡ Los Angeles ✡  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "...                               ...                             ...   \n",
       "14635                               0                               0   \n",
       "14636                               0                               0   \n",
       "14637                               0                               0   \n",
       "14638                               0                               0   \n",
       "14639                               0                               0   \n",
       "\n",
       "       tweet_location_✨  tweet_location_❤  tweet_location_サマセット、ニュージャージー州  \\\n",
       "0                     0                 0                               0   \n",
       "1                     0                 0                               0   \n",
       "2                     0                 0                               0   \n",
       "3                     0                 0                               0   \n",
       "4                     0                 0                               0   \n",
       "...                 ...               ...                             ...   \n",
       "14635                 0                 0                               0   \n",
       "14636                 0                 0                               0   \n",
       "14637                 0                 0                               0   \n",
       "14638                 0                 0                               0   \n",
       "14639                 0                 0                               0   \n",
       "\n",
       "       tweet_location_명동서식 37.56638,126.984994  \n",
       "0                                            0  \n",
       "1                                            0  \n",
       "2                                            0  \n",
       "3                                            0  \n",
       "4                                            0  \n",
       "...                                        ...  \n",
       "14635                                        0  \n",
       "14636                                        0  \n",
       "14637                                        0  \n",
       "14638                                        0  \n",
       "14639                                        0  \n",
       "\n",
       "[14640 rows x 5358 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dummy variables for categorical columns\n",
    "tweets = pd.get_dummies(tweets, columns=['negativereason','negativereason_confidence','airline_sentiment_gold',\n",
    "                                         'negativereason_gold','tweet_coord','tweet_location'])\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "099c120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>negativereason_Bad Flight</th>\n",
       "      <th>negativereason_Can't Tell</th>\n",
       "      <th>negativereason_Cancelled Flight</th>\n",
       "      <th>negativereason_Customer Service Issue</th>\n",
       "      <th>negativereason_Damaged Luggage</th>\n",
       "      <th>negativereason_Flight Attendant Complaints</th>\n",
       "      <th>negativereason_Flight Booking Problems</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_location_✈ Check ☟ out ☟ my blog ☟</th>\n",
       "      <th>tweet_location_✈️ Birmingham ✈️ Brooklyn ✈️</th>\n",
       "      <th>tweet_location_✈️FL/NJ/NYC</th>\n",
       "      <th>tweet_location_✈️✈️</th>\n",
       "      <th>tweet_location_✖️ || 4/5 || ✖️</th>\n",
       "      <th>tweet_location_✡ Los Angeles ✡</th>\n",
       "      <th>tweet_location_✨</th>\n",
       "      <th>tweet_location_❤</th>\n",
       "      <th>tweet_location_サマセット、ニュージャージー州</th>\n",
       "      <th>tweet_location_명동서식 37.56638,126.984994</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>positive</td>\n",
       "      <td>0.3487</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14637</th>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 5352 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment  airline_sentiment_confidence  retweet_count  \\\n",
       "0               neutral                        1.0000              0   \n",
       "1              positive                        0.3486              0   \n",
       "2               neutral                        0.6837              0   \n",
       "3              negative                        1.0000              0   \n",
       "4              negative                        1.0000              0   \n",
       "...                 ...                           ...            ...   \n",
       "14635          positive                        0.3487              0   \n",
       "14636          negative                        1.0000              0   \n",
       "14637           neutral                        1.0000              0   \n",
       "14638          negative                        1.0000              0   \n",
       "14639           neutral                        0.6771              0   \n",
       "\n",
       "       negativereason_Bad Flight  negativereason_Can't Tell  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              1                          0   \n",
       "4                              0                          1   \n",
       "...                          ...                        ...   \n",
       "14635                          0                          0   \n",
       "14636                          0                          0   \n",
       "14637                          0                          0   \n",
       "14638                          0                          0   \n",
       "14639                          0                          0   \n",
       "\n",
       "       negativereason_Cancelled Flight  negativereason_Customer Service Issue  \\\n",
       "0                                    0                                      0   \n",
       "1                                    0                                      0   \n",
       "2                                    0                                      0   \n",
       "3                                    0                                      0   \n",
       "4                                    0                                      0   \n",
       "...                                ...                                    ...   \n",
       "14635                                0                                      0   \n",
       "14636                                0                                      1   \n",
       "14637                                0                                      0   \n",
       "14638                                0                                      1   \n",
       "14639                                0                                      0   \n",
       "\n",
       "       negativereason_Damaged Luggage  \\\n",
       "0                                   0   \n",
       "1                                   0   \n",
       "2                                   0   \n",
       "3                                   0   \n",
       "4                                   0   \n",
       "...                               ...   \n",
       "14635                               0   \n",
       "14636                               0   \n",
       "14637                               0   \n",
       "14638                               0   \n",
       "14639                               0   \n",
       "\n",
       "       negativereason_Flight Attendant Complaints  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "14635                                           0   \n",
       "14636                                           0   \n",
       "14637                                           0   \n",
       "14638                                           0   \n",
       "14639                                           0   \n",
       "\n",
       "       negativereason_Flight Booking Problems  ...  \\\n",
       "0                                           0  ...   \n",
       "1                                           0  ...   \n",
       "2                                           0  ...   \n",
       "3                                           0  ...   \n",
       "4                                           0  ...   \n",
       "...                                       ...  ...   \n",
       "14635                                       0  ...   \n",
       "14636                                       0  ...   \n",
       "14637                                       0  ...   \n",
       "14638                                       0  ...   \n",
       "14639                                       0  ...   \n",
       "\n",
       "       tweet_location_✈ Check ☟ out ☟ my blog ☟  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "...                                         ...   \n",
       "14635                                         0   \n",
       "14636                                         0   \n",
       "14637                                         0   \n",
       "14638                                         0   \n",
       "14639                                         0   \n",
       "\n",
       "       tweet_location_✈️ Birmingham ✈️ Brooklyn ✈️  \\\n",
       "0                                                0   \n",
       "1                                                0   \n",
       "2                                                0   \n",
       "3                                                0   \n",
       "4                                                0   \n",
       "...                                            ...   \n",
       "14635                                            0   \n",
       "14636                                            0   \n",
       "14637                                            0   \n",
       "14638                                            0   \n",
       "14639                                            0   \n",
       "\n",
       "       tweet_location_✈️FL/NJ/NYC  tweet_location_✈️✈️  \\\n",
       "0                               0                    0   \n",
       "1                               0                    0   \n",
       "2                               0                    0   \n",
       "3                               0                    0   \n",
       "4                               0                    0   \n",
       "...                           ...                  ...   \n",
       "14635                           0                    0   \n",
       "14636                           0                    0   \n",
       "14637                           0                    0   \n",
       "14638                           0                    0   \n",
       "14639                           0                    0   \n",
       "\n",
       "       tweet_location_✖️ || 4/5 || ✖️  tweet_location_✡ Los Angeles ✡  \\\n",
       "0                                   0                               0   \n",
       "1                                   0                               0   \n",
       "2                                   0                               0   \n",
       "3                                   0                               0   \n",
       "4                                   0                               0   \n",
       "...                               ...                             ...   \n",
       "14635                               0                               0   \n",
       "14636                               0                               0   \n",
       "14637                               0                               0   \n",
       "14638                               0                               0   \n",
       "14639                               0                               0   \n",
       "\n",
       "       tweet_location_✨  tweet_location_❤  tweet_location_サマセット、ニュージャージー州  \\\n",
       "0                     0                 0                               0   \n",
       "1                     0                 0                               0   \n",
       "2                     0                 0                               0   \n",
       "3                     0                 0                               0   \n",
       "4                     0                 0                               0   \n",
       "...                 ...               ...                             ...   \n",
       "14635                 0                 0                               0   \n",
       "14636                 0                 0                               0   \n",
       "14637                 0                 0                               0   \n",
       "14638                 0                 0                               0   \n",
       "14639                 0                 0                               0   \n",
       "\n",
       "       tweet_location_명동서식 37.56638,126.984994  \n",
       "0                                            0  \n",
       "1                                            0  \n",
       "2                                            0  \n",
       "3                                            0  \n",
       "4                                            0  \n",
       "...                                        ...  \n",
       "14635                                        0  \n",
       "14636                                        0  \n",
       "14637                                        0  \n",
       "14638                                        0  \n",
       "14639                                        0  \n",
       "\n",
       "[14640 rows x 5352 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.drop(columns=['tweet_id','text','tweet_created','user_timezone','airline','name'], axis=1)\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "812535fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression:  0.908948087431694\n",
      "Accuracy of logistic regression:  0.908948087431694\n"
     ]
    }
   ],
   "source": [
    "# Define the vector of targets and matrix of features\n",
    "y = tweets.airline_sentiment\n",
    "X = tweets.drop('airline_sentiment', axis=1)\n",
    "\n",
    "# Build a logistic regression model and calculate the accuracy\n",
    "log_reg = LogisticRegression(max_iter=500).fit(X, y)\n",
    "print('Accuracy of logistic regression: ', log_reg.score(X, y))\n",
    "\n",
    "# Create an array of prediction a\n",
    "y_predict = log_reg.predict(X)\n",
    "\n",
    "# Print the accuracy using accuracy score\n",
    "print('Accuracy of logistic regression: ', accuracy_score(y, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2a278320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set:  0.910433743169399\n",
      "Accuracy on test set:  0.8531420765027322\n"
     ]
    }
   ],
   "source": [
    "# Perform the train-test split on tweets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a logistic regression model and print out the accuracy\n",
    "log_reg = LogisticRegression(max_iter=500).fit(X_train,y_train)\n",
    "print('Accuracy on train set: ', log_reg.score(X_train, y_train))\n",
    "print('Accuracy on test set: ', log_reg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9293197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score test set:  0.8474499089253188\n",
      "Confusion matrix test set: \n",
      " <sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay object at 0x1488d7df0>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAGwCAYAAABb6kfNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAABALUlEQVR4nO3deVxU5f4H8M+wzSAwI7uiiLghiguCKZpmWZSWV7NbmuVSUJKmKdnitXK5KdUtRStQKzX7qZfKtSKVbq6ZlYiZijsCKsgmjIIsM3N+fxBTI6POMBsz5/N+vc7rXp55nnO+p1G/PMs5j0QQBAFERETkEJxsHQARERGZDxM7ERGRA2FiJyIiciBM7ERERA6EiZ2IiMiBMLETERE5ECZ2IiIiB+Ji6wBModFocPnyZXh5eUEikdg6HCIiMpIgCLh27RqCgoLg5GS5vmZ1dTVqa2tNPo+bmxtkMpkZIrIcu07sly9fRnBwsK3DICIiE+Xn56Nt27YWOXd1dTVCQzxRWKQ2+VytWrVCTk5Os07udp3Yvby8AAC5h9tD7slZBUf3aJcetg6BiMxMhTrsR7r233NLqK2tRWGRGrmZ7SH3anquUF7TICTqAmpra5nYLaVh+F3u6WTSl0X2wUXiausQiMjc/nypuTWmUz29JPD0avp1NLCPKV+7TuxERESGUgsaqE3YHUUtaMwXjAUxsRMRkShoIECDpmd2U9paE8eviYiIHAh77EREJAoaaGDKYLppra2HiZ2IiERBLQhQC00fTjelrTVxKJ6IiMiBsMdORESiIJbFc0zsREQkChoIUIsgsXMonoiIyIEwsRMRkSg0DMWbcjRFSkoKQkNDIZPJEBUVhX379t22fk1NDebMmYOQkBBIpVJ07NgRq1atMvh6HIonIiJRsMWq+LS0NMyYMQMpKSkYOHAgVqxYgWHDhuHEiRNo166d3jZPPPEErly5gs8++wydOnVCUVERVCqVwddkYiciIrKQxYsXIy4uDvHx8QCA5ORk7NixA6mpqUhKSmpUf/v27dizZw/Onz8PHx8fAED79u2NuiaH4omISBQ0ZjgAQKlU6hw1NTV6r1dbW4vMzEzExsbqlMfGxuLAgQN622zbtg3R0dF477330KZNG3Tp0gWzZs3CjRs3DL5P9tiJiEgU1Cauim9oGxwcrFM+d+5czJs3r1H9kpISqNVqBAYG6pQHBgaisLBQ7zXOnz+P/fv3QyaTYfPmzSgpKcGUKVNQVlZm8Dw7EzsREYmCWoCJu7vV/29+fj7kcrm2XCqV3rbdzVvSCoJwy21qNRoNJBIJ1q1bB4VCAaB+OP+f//wnPv74Y7i7u98xTg7FExERGUEul+sct0rsfn5+cHZ2btQ7LyoqatSLb9C6dWu0adNGm9QBIDw8HIIg4OLFiwbFx8RORESiYK45dkO5ubkhKioKGRkZOuUZGRkYMGCA3jYDBw7E5cuXcf36dW3Z6dOn4eTkhLZt2xp0XSZ2IiISBQ0kUJtwaKB/+Px2EhMT8emnn2LVqlXIzs7GzJkzkZeXh4SEBADA7NmzMWHCBG39cePGwdfXF8888wxOnDiBvXv34pVXXsGzzz5r0DA8wDl2IiIiixkzZgxKS0uxYMECFBQUICIiAunp6QgJCQEAFBQUIC8vT1vf09MTGRkZmDZtGqKjo+Hr64snnngCb7/9tsHXlAiCnexDp4dSqYRCocDV0x0g9+Lgg6N7MKi3rUMgIjNTCXXYja2oqKjQWZBmTg254tDxQHiakCuuX9MguvsVi8ZqDuyxExGRKDQMqZvS3h6wm0tERORA2GMnIiJREEuPnYmdiIhEQSNIoBGanpxNaWtNHIonIiJyIOyxExGRKHAonoiIyIGo4QS1CQPVajPGYklM7EREJAqCiXPsAufYiYiIyNrYYyciIlHgHDsREZEDUQtOUAsmzLHbyQvYORRPRETkQNhjJyIiUdBAAo0J/VkN7KPLzsRORESiIJY5dg7FExERORD22ImISBRMXzzHoXgiIqJmo36O3YRNYDgUT0RERNbGHjsREYmCxsR3xXNVPBERUTPCOXYiIiIHooGTKJ5j5xw7ERGRA2GPnYiIREEtSKA2YetVU9paExM7ERGJgtrExXNqDsUTERGRtbHHTkREoqARnKAxYVW8hqviiYiImg8OxRMREZHdYY+diIhEQQPTVrZrzBeKRTGxExGRKJj+ghr7GOS2jyiJiIjIIOyxExGRKJj+rnj76AszsRMRkSiIZT92JnYiIhIF9tjJar5Z44uvUgNQVuSKkC7VSFhwCT36Vd6yfm2NBOuWBOLHjT64WuwCv9Z1eHL6FTz4ZBkAYH+6Av9dFojLF6RQ1QFtQmvxWEIR7v/nVWvdEpnBIxNL8PgLxfAJqEPuaRmWvxWEY7962josshB+32QuNv/1IyUlBaGhoZDJZIiKisK+fftsHZJV7d7aEsvntsGT068gZecpRPSrxBtPdUDRRddbtlk4uT2O7PfCzA/y8Om+k3g9JRdtO1VrP/dqqcaTL11B8jensfx/pxA7thQfzGyHQ7u9rHFLZAb3/OMqEuZfxoZlAZgS2wXHfvHA2+ty4N+m1tahkQXw+7aOhhfUmHLYA5tGmZaWhhkzZmDOnDnIysrCoEGDMGzYMOTl5dkyLKvatNIfDz5ZhmFPlaFd5xq8sOAS/IPq8O1aP731f9vlhT8OeuLfX5xHn8HX0Sq4Fl0jq9C9b5W2Tq8B1zFwWAXada5BUPtaPBpfgg7hN3D8Vw9r3RaZaPTzJdixwQfb1/si/6wMy+e2QfFlVzwyodTWoZEF8Pu2Do0gMfmwBzZN7IsXL0ZcXBzi4+MRHh6O5ORkBAcHIzU11ZZhWU1drQRnjrZA1D3XdMqj7rmGE4f0J+GDOxXo3LMKX6UEYFyfbnj27q5YOT8INTf0/4ETBCBrnyfyz0kR0e+62e+BzM/FVYPOPauQuUd3hCVzjxe6Rd96iobsE79vMjebzbHX1tYiMzMTr7/+uk55bGwsDhw4oLdNTU0NampqtD8rlUqLxmhpyjJnaNQStPSr0ylv6V+Hq0X6h80Lct1w/DcPuMk0eOuzC1CWOeOj2cG4Vu6Ml5fka+tVKp0wrk931NU6wclZwLRFFxF1DxO7PZD7qOHsApSX6P71LC92gXeAykZRkaXw+7YejYnD6fbyghqbJfaSkhKo1WoEBgbqlAcGBqKwsFBvm6SkJMyfP98a4VmV5KbOtiBIcKunKgRNff3XP8qFh7z+BYfPz7uEt59rjxcXXYTUvX6TAndPDVIyTqG60hlZ+z2xYn4btAqpRa8BTO724uaNpCQSwE72oKAm4Pdteabv7mYfid3mUUpuymqCIDQqazB79mxUVFRoj/z8fL317IXcRw0nZwFXi3UXylWUuMDbX/9v6j6BKvi2qtMmdQBo17kagiBBScFf53Fyql8N3zHiBv6ZUIxBD5cj7cMAy9wImZWyzBlqFRr9GVD4qXC1mA+yOBp+32RuNkvsfn5+cHZ2btQ7LyoqatSLbyCVSiGXy3UOe+bqJqBzzyoc3qs77H54763n1rr3rURZoStuVP711V08J4WTkwC/1nV62wD1vYG6Wpv/HkcGUNU54czRFugzWHftRZ/Bt157QfaL37f1qCEx+bAHNvuX3s3NDVFRUcjIyNApz8jIwIABA2wUlfWNfr4Y29f7YMcGH+SdkWL53CAUXXLFwxNKAACrFrXGe9Pbaevf++hVeHmr8MHMdsg9LcUfBz3w6dtBiB1bph2G/++HAcjc44mCXDfknZFi4wp//PC1D+4bXWaTeyTjbVrph4fGlSF2bCmCO1Vj8rxLCGhTh+/W+to6NLIAft/W0TAUb8phD2w6zpOYmIjx48cjOjoaMTExWLlyJfLy8pCQkGDLsKxqyMhyXLvqjHVLWqGsyAUhYdV4+//OI7Btfe+7rMgVxZfctPXdPTRI+u85pLzRFtMeCoOXtwqD/1GOSa8WaOtUVznho38Fo6TAFW4yDYI71uDVD3MxZGS5tW+PmmjPNm94eavx1Mwr8AlQIfeUDG88HYqiv/1ZIMfB75vMSSIINy/ZsK6UlBS89957KCgoQEREBJYsWYLBgwcb1FapVEKhUODq6Q6Qe9nHb1LUdA8G9bZ1CERkZiqhDruxFRUVFRabXm3IFW/9cj9knrd++dedVF+vw4J+P1g0VnOw+cqMKVOmYMqUKbYOg4iIHJxYVsXbPLETERFZg1g2gbGPKImIiMggTOxERCQKwp/7sTf1EJr4uJsxm53t3r0bEomk0XHy5EmDr8eheCIiEgVbDMU3bHaWkpKCgQMHYsWKFRg2bBhOnDiBdu3a3bLdqVOndBbo+fv7G3xN9tiJiIgspKmbnQUEBKBVq1baw9nZ2eBrMrETEZEomGvbVqVSqXP8fXOyv2vY7Cw2Nlan/HabnTWIjIxE69atMXToUOzatcuo+2RiJyIiUVD/ububKQcABAcHQ6FQaI+kpCS912vKZmetW7fGypUrsXHjRmzatAlhYWEYOnQo9u7da/B9co6diIjICPn5+Trz31Kp9Lb1jdnsLCwsDGFhYdqfY2JikJ+fj/fff9/gl7exx05ERKJgrqH4mzcju1Vib8pmZ/r0798fZ86cMbg+EzsREYmCBk4mH8Yw12ZnWVlZaN26tcH1ORRPRERkIXfa7Gz27Nm4dOkS1q5dCwBITk5G+/bt0b17d9TW1uL//u//sHHjRmzcuNHgazKxExGRKKgFCdRC0/dUb0rbMWPGoLS0FAsWLNBudpaeno6QkBAAQEFBAfLy8rT1a2trMWvWLFy6dAnu7u7o3r07vvvuOwwfPtzga9p8dzdTcHc3ceHubkSOx5q7u03e+xikJuzuVnO9DisGb+TubkRERM2BYOLubgI3gSEiIiJrY4+diIhEQQ0J1E3cyKWhvT1gYiciIlHQCNA+i97U9vaAQ/FEREQOhD12IiISBY2Ji+dMaWtNTOxERCQKGkigMWGe3JS21mQfv34QERGRQdhjJyIiUbDFm+dsgYmdiIhEQSxz7PYRJRERERmEPXYiIhIFDSSmPcduJ4vnmNiJiEgUBBNXxQtM7ERERM2HRjCxx24ni+c4x05ERORA2GMnIiJREMuqeCZ2IiISBQ7FExERkd1hj52IiERBLO+KZ2InIiJR4FA8ERER2R322ImISBTE0mNnYiciIlEQS2LnUDwREZEDYY+diIhEQSw9diZ2IiISBQGmPbImmC8Ui2JiJyIiURBLj51z7ERERA6EPXYiIhIFsfTYmdiJiEgUxJLYORRPRETkQNhjJyIiURBLj52JnYiIREEQJBBMSM6mtLUmDsUTERE5EPbYiYhIFLgfOxERkQMRyxw7h+KJiIgcCHvsREQkCmJZPMfETkREoiCWoXgmdiIiEgWx9Ng5x05ERORAHKLH/miXHnCRuNo6DLKwysf62ToEsiLFLxdtHQJZg6YGuGSdSwkmDsXbS4/dIRI7ERHRnQgABMG09vaAQ/FEREQOhD12IiISBQ0kkPDNc0RERI6Bq+KJiIjI7rDHTkREoqARJJCI4AU17LETEZEoCILpR1OkpKQgNDQUMpkMUVFR2Ldvn0HtfvrpJ7i4uKB3795GXY+JnYiIyELS0tIwY8YMzJkzB1lZWRg0aBCGDRuGvLy827arqKjAhAkTMHToUKOvycRORESi0LB4zpTDWIsXL0ZcXBzi4+MRHh6O5ORkBAcHIzU19bbtJk+ejHHjxiEmJsboazKxExGRKJgrsSuVSp2jpqZG7/Vqa2uRmZmJ2NhYnfLY2FgcOHDglnGuXr0a586dw9y5c5t0n0zsREQkCg27u5lyAEBwcDAUCoX2SEpK0nu9kpISqNVqBAYG6pQHBgaisLBQb5szZ87g9ddfx7p16+Di0rT17VwVT0REZIT8/HzI5XLtz1Kp9Lb1JRLdIXxBEBqVAYBarca4ceMwf/58dOnSpcnxMbETEZEomLKyvaE9AMjlcp3Efit+fn5wdnZu1DsvKipq1IsHgGvXruHQoUPIysrCiy++CADQaDQQBAEuLi7YuXMn7rvvvjtel4mdiIhEoT6xm/LmOePqu7m5ISoqChkZGXj00Ue15RkZGRg5cmSj+nK5HH/88YdOWUpKCn788Ud8/fXXCA0NNei6TOxEREQWkpiYiPHjxyM6OhoxMTFYuXIl8vLykJCQAACYPXs2Ll26hLVr18LJyQkRERE67QMCAiCTyRqV3w4TOxERiYIt3hU/ZswYlJaWYsGCBSgoKEBERATS09MREhICACgoKLjjM+3GkgiCKTMOtqVUKqFQKDAEI+EicbV1OGRhlY/1s3UIZEWKXy7aOgSyApWmBj9cWo6KigqD5q2boiFXdPxiNpxbyJp8HnVVNc6NT7JorObAx92IiIgcCIfiiYhIFMSybSsTOxERiYPw52FKezvAxE5EROJgYo8ddtJj5xw7ERGRA2GPnYiIRMFcb55r7pjYiYhIFMSyeI5D8URERA6EPXYiIhIHQWLaAjg76bEzsRMRkSiIZY6dQ/FEREQOhD12IiISB76ghoiIyHGIZVW8QYl92bJlBp9w+vTpTQ6GiIiITGNQYl+yZIlBJ5NIJEzsRETUfNnJcLopDErsOTk5lo6DiIjIosQyFN/kVfG1tbU4deoUVCqVOeMhIiKyDMEMhx0wOrFXVVUhLi4OLVq0QPfu3ZGXlwegfm79nXfeMXuAREREZDijE/vs2bPx+++/Y/fu3ZDJZNry+++/H2lpaWYNjoiIyHwkZjiaP6Mfd9uyZQvS0tLQv39/SCR/3WS3bt1w7tw5swZHRERkNiJ5jt3oHntxcTECAgIalVdWVuokeiIiIrI+oxN737598d1332l/bkjmn3zyCWJiYswXGRERkTmJZPGc0UPxSUlJeOihh3DixAmoVCosXboUx48fx88//4w9e/ZYIkYiIiLTiWR3N6N77AMGDMBPP/2EqqoqdOzYETt37kRgYCB+/vlnREVFWSJGIiIiMlCT3hXfo0cPfP755+aOhYiIyGLEsm1rkxK7Wq3G5s2bkZ2dDYlEgvDwcIwcORIuLtxThoiImimRrIo3OhMfO3YMI0eORGFhIcLCwgAAp0+fhr+/P7Zt24YePXqYPUgiIiIyjNFz7PHx8ejevTsuXryIw4cP4/Dhw8jPz0fPnj3x/PPPWyJGIiIi0zUsnjPlsANG99h///13HDp0CN7e3toyb29vLFy4EH379jVrcEREROYiEeoPU9rbA6N77GFhYbhy5Uqj8qKiInTq1MksQREREZmdSJ5jNyixK5VK7bFo0SJMnz4dX3/9NS5evIiLFy/i66+/xowZM/Duu+9aOl4iIiK6DYOG4lu2bKnzulhBEPDEE09oy4Q/nwEYMWIE1Gq1BcIkIiIykUheUGNQYt+1a5el4yAiIrIsPu72l3vuucfScRAREZEZNPmNMlVVVcjLy0Ntba1Oec+ePU0OioiIyOzYY9evuLgYzzzzDL7//nu9n3OOnYiImiWRJHajH3ebMWMGrl69ioMHD8Ld3R3bt2/H559/js6dO2Pbtm2WiJGIiIgMZHSP/ccff8TWrVvRt29fODk5ISQkBA888ADkcjmSkpLw8MMPWyJOIiIi04hkVbzRPfbKykoEBAQAAHx8fFBcXAygfse3w4cPmzc6IiIiM2l485wphz0wusceFhaGU6dOoX379ujduzdWrFiB9u3bY/ny5WjdurUlYqS/eWRiCR5/oRg+AXXIPS3D8reCcOxXT1uHRQZ6dNBxPDn0KHzlVbhQ4I2lm2Jw9Jz+vze+8iq8+OjPCAsuQVv/Cny9JwLLNg1oVM/TvQbPP/IbBvfKgVeLWhSUeuGjzf1x8EQ7S98O/c3Dj+Vi9Pjz8PGtQd55T6xc0g3Hj/jcsn5EZCmem5GNdh2uo6xEiq+/6IDvN4XorTv4gct4beER/LwnEG+/EqUtd2+hwtOTT2PAkEIovGtx/rQcKz7ohjPZLc19e2RHmjTHXlBQAACYO3cutm/fjnbt2mHZsmVYtGiRUefau3cvRowYgaCgIEgkEmzZssXYcETlnn9cRcL8y9iwLABTYrvg2C8eeHtdDvzb1N65MdncfX3OYfron7F2RySefXc0fj/XCu+/8D0Cva/rre/qokb5dXes3RmJs5d89dZxcVZjydR0tPK9hjc/ewDj/v0E3tswGCUVHpa8FbrJoPsv47nEE0hb3QnTx9+NY0d8MD/5N/gH3tBbPzCoCvOTD+HYER9MH3830tZ0wuSXT2DAvQWN6vq3uoG46SdxLMu70WfT5/yByH4leH9eb0wdNwiHf/HDwo9/ha9/tdnv0SHwlbL6PfXUU5g0aRIAIDIyEhcuXMBvv/2G/Px8jBkzxqhzVVZWolevXvjoo4+MDUOURj9fgh0bfLB9vS/yz8qwfG4bFF92xSMTSm0dGhlg7L1H8e3PYfj2567IveKNZZsGoOiqJ0bdfUJv/cIyLyzdOADbf+2Cymo3vXUe7n8K8hbVmL3yQfyR0wpXrnrh6PlWt/xFgCzj0XE52LktGDu3BiP/gic+WdINJVdkGP5Yrt76w0fnobhQhk+WdEP+BU/s3BqMjG/aYvTTOTr1nJwEvLLgCNZ90hmFl1rofOYmVWPgvYVY/WFXHM/yQcFFD6z/pAuuXHa/5XVJHJr8HHuDFi1aoE+fPk1qO2zYMAwbNszUEETBxVWDzj2rkPZRgE555h4vdIuutFFUZCgXZzW6BJfg/zJ665T/drItIkIbb6pkqLt75OLYhUC8/MR+3N0jF+XXZcjI7IR1Gb2gEYz+vZ2awMVFg05dlfhqbUed8sO/+CO8Z7neNl17XMXhX/x16x/0R+w/LsLZWQO1uv67ezLuDCrK3bBzWzC69y7Tqe/sLMDZRUBtre73XFPjjG69rpp4V45JAhN3dzNbJJZlUGJPTEw0+ISLFy9ucjB3UlNTg5qaGu3PSqXSYtdqbuQ+aji7AOUlul9ZebELvANUNoqKDKXwqIaLs4Cya+465WXX3OErr2ryeYP8lOjjcx0ZhzrhleUPoa1/BRKf+AnOThqs2R515xOQyeQta+HsIqC8VKpTXl7mBm/fGr1tvH1rUF6mOwpTXiqFi4sAectaXC2VIbxnGWL/cRHTnr5b7zluVLkg+2hLjH32LPJzPFFeJsU9sZcR1r0cl/M5FSNmBiX2rKwsg072941iLCEpKQnz58+36DWaO+Gm3zYlEtjNvA8Bwk2Py0ggmPT1OUmA8msyvLdhEDSCE07l+8NPUYUnh/7OxG5lN3+PEknjv6869Rs1aCiQwL2FCrMW/I5liyKgrNA/DQMA78/thRlv/oEv0n+EWiXB2VNy7NkRhI5h4un0GEUkj7vZ1SYws2fP1hk9UCqVCA4OtmFE1qMsc4ZaBXj76/bOFX4qXC02eUaFLKyiUgaVWtKod+7tVY0yZYtbtLqzkooWUGucdIbdc6+0hJ/iBlyc1VCpnZt8bjKMstwNapWkUe9c4V2L8jKp3jZXS6Xw9tVd9NrSpxYqlQTKcleEdLiOVkE3MPeDTO3nEqf6xL/twPd4/vHBKLzkgcJLHng9oT+kMhVaeKhwtVSG1xZm4cpl3ZEh+pNI3jxnVxlBKpVCKtX/F8XRqeqccOZoC/QZfA0Htiu05X0GX8PPOxS3aUnNgUrtjNP5fujb9RL2Hg3VlkeHXcT+P9o3+bx/5ATigaizkEgE7WhAsH8FSipaMKlbiUrlhLMn5Yi8qwQ/726lLY+8qwQH9wbobXPyD2/cdXeRTllkvxKcyVZArXZCfq4HpowdpPP5+BdOw72FCis/6IaSK7qJu6baBTXVLvD0qkOf/sVY/WFXM90d2SO7Suxit2mlH15Zlo/TR92RfcgDw58uRUCbOny3liug7cF/d/XEm+N34WSeH47lBOIfA7MR6HMdW/aHAwAmj/gV/i0r8fYX92rbdGpTAgBwl9ahpWc1OrUpgUrtjAuF9Y8+bdnXDf8cfBwvPXYAG/d0R9sAJcbHHsHXe7pb/wZFbPP6ULw8/3ecyVbg5B/eeOjRPPi3uoH0P59LnzjlJHwDarB4Xi8AQPqmdnjk8VzEzziBHVvaoWuPq4j9Rz7ee6M3AKCu1hm55710rlF5rf6f67+X9+lfDAmAi3keaN22EnHTT+JSrgcyvmlr+Zu2R+yxW97169dx9uxZ7c85OTk4cuQIfHx80K4dX65xsz3bvOHlrcZTM6/AJ0CF3FMyvPF0KIou3XoOjpqPHw93hMKjGpMeOgxfeRVyCnzwSuowXLla/w+1r6Kq0TPta17fpP3/XduVILbvWRSUeuLxeeMAAEXlnpj58XBMH/0z1szeiJLyFvhqTwTWZfSy3o0R9v0QBLmiDk/GnYWPXw1yz3li7sy+KC6s71n7+NXoPNN+5XILzJ0RjedmZuORf+ahtESKFR90w4Fdxr3kq4WnCpOmnIJfQDWuKV3x04+tsDa1i3ZVPeky9e1xTW2bkpKC//znPygoKED37t2RnJyMQYMG6a27f/9+vPbaazh58iSqqqoQEhKCyZMnY+bMmUbEKdxueYdl7d69G/fee2+j8okTJ2LNmjV3bK9UKqFQKDAEI+EicbVAhNScVD7Wz9YhkBUpfrlo6xDIClSaGvxwaTkqKiogl8stco2GXNF+4UI4yWRNPo+muhoX5swxKta0tDSMHz8eKSkpGDhwIFasWIFPP/0UJ06c0NuBzcrKwsmTJ9GzZ094eHhg//79mDx5MpYsWYLnn3/eoGvaNLGbioldXJjYxYWJXRysmtjfNkNif8O4xN6vXz/06dMHqamp2rLw8HCMGjUKSUlJBp1j9OjR8PDwwBdffGFQ/SaN13zxxRcYOHAggoKCkJtb/4aj5ORkbN26tSmnIyIisjwzvVJWqVTqHH9/v8rf1dbWIjMzE7GxsTrlsbGxOHDggEEhZ2Vl4cCBA7jnnnsMvk2jE3tqaioSExMxfPhwlJeXQ61WAwBatmyJ5ORkY09HRERkV4KDg6FQKLTHrXreJSUlUKvVCAwM1CkPDAxEYWHhba/Rtm1bSKVSREdHY+rUqYiPjzc4PqMXz3344Yf45JNPMGrUKLzzzjva8ujoaMyaNcvY0xEREVmFuRbP5efn6wzF3+kx7Jtf3iYIwh1f6LZv3z5cv34dBw8exOuvv45OnTrhySefNChOoxN7Tk4OIiMjG5VLpVJUVvKd5URE1EyZ6c1zcrncoDl2Pz8/ODs7N+qdFxUVNerF3yw0tP59Fz169MCVK1cwb948gxO70UPxoaGhOHLkSKPy77//Ht26dTP2dERERNZh5W1b3dzcEBUVhYyMDJ3yjIwMDBgwwPCwBeGW8/j6GN1jf+WVVzB16lRUV1dDEAT8+uuv2LBhA5KSkvDpp58aezoiIiKHlZiYiPHjxyM6OhoxMTFYuXIl8vLykJCQAKD+VemXLl3C2rVrAQAff/wx2rVrh65d698euH//frz//vuYNm2awdc0OrE/88wzUKlUePXVV1FVVYVx48ahTZs2WLp0KcaOHWvs6YiIiKzCFi+oGTNmDEpLS7FgwQIUFBQgIiIC6enpCAmpfythQUEB8vLytPU1Gg1mz56NnJwcuLi4oGPHjnjnnXcwefJkI+I04Tn2kpISaDQaBATofx+ypfE5dnHhc+ziwufYxcGaz7F3eGuRyc+xn1/wL4vGag4mvVLWz8/PXHEQERGRGRid2ENDQ2+7TP/8+fMmBURERGQRJg7FO+wmMDNmzND5ua6uDllZWdi+fTteeeUVc8VFRERkXtzdTb+XXnpJb/nHH3+MQ4cOmRwQERERNZ3Z9vYbNmwYNm7caK7TERERmZeVn2O3FbPtx/7111/Dx8fHXKcjIiIyK1vtx25tRif2yMhIncVzgiCgsLAQxcXFSElJMWtwREREZByjE/uoUaN0fnZycoK/vz+GDBmifVMOERER2YZRiV2lUqF9+/Z48MEH0apVK0vFREREZH4iWRVv1OI5FxcXvPDCC0a9jJ6IiKg5aJhjN+WwB0aviu/Xrx+ysrIsEQsRERGZyOg59ilTpuDll1/GxYsXERUVBQ8PD53Pe/bsabbgiIiIzMpOet2mMDixP/vss0hOTsaYMWMAANOnT9d+JpFIIAgCJBIJ1Gq1+aMkIiIylUjm2A1O7J9//jneeecd5OTkWDIeIiIiMoHBib1hd9eGPWSJiIjsCV9Qo8ftdnUjIiJq1jgU31iXLl3umNzLyspMCoiIiIiazqjEPn/+fCgUCkvFQkREZDEcitdj7NixCAgIsFQsREREliOSoXiDX1DD+XUiIqLmz+hV8URERHZJJD12gxO7RqOxZBxEREQWxTl2IiIiRyKSHrvRm8AQERFR88UeOxERiYNIeuxM7EREJApimWPnUDwREZEDYY+diIjEgUPxREREjoND8URERGR32GMnIiJx4FA8ERGRAxFJYudQPBERkQNhj52IiERB8udhSnt7wMRORETiIJKheCZ2IiISBT7uRkRERHaHPXYiIhIHDsUTERE5GDtJzqbgUDwREZEDYY+diIhEQSyL55jYiYhIHEQyx86heCIiIgfCHjsREYkCh+KJiIgcCYfiiYiIyN6wx052w+PSDVuHQNbk4mzrCMgaNNb7njkUT0RE5Eg4FE9ERORABDMcTZCSkoLQ0FDIZDJERUVh3759t6y7adMmPPDAA/D394dcLkdMTAx27Nhh1PWY2ImIiCwkLS0NM2bMwJw5c5CVlYVBgwZh2LBhyMvL01t/7969eOCBB5Ceno7MzEzce++9GDFiBLKysgy+JofiiYhIFGwxx7548WLExcUhPj4eAJCcnIwdO3YgNTUVSUlJjeonJyfr/Lxo0SJs3boV33zzDSIjIw26JnvsREQkDmYailcqlTpHTU2N3svV1tYiMzMTsbGxOuWxsbE4cOCAQSFrNBpcu3YNPj4+Bt8mEzsREZERgoODoVAotIe+njcAlJSUQK1WIzAwUKc8MDAQhYWFBl3rgw8+QGVlJZ544gmD4+NQPBERiYJEECARmj4W39A2Pz8fcrlcWy6VSm/fTiLR+VkQhEZl+mzYsAHz5s3D1q1bERAQYHCcTOxERCQOZnrcTS6X6yT2W/Hz84Ozs3Oj3nlRUVGjXvzN0tLSEBcXh6+++gr333+/UWFyKJ6IiMgC3NzcEBUVhYyMDJ3yjIwMDBgw4JbtNmzYgEmTJmH9+vV4+OGHjb4ue+xERCQKtlgVn5iYiPHjxyM6OhoxMTFYuXIl8vLykJCQAACYPXs2Ll26hLVr1wKoT+oTJkzA0qVL0b9/f21v393dHQqFwqBrMrETEZE42ODNc2PGjEFpaSkWLFiAgoICREREID09HSEhIQCAgoICnWfaV6xYAZVKhalTp2Lq1Kna8okTJ2LNmjUGXZOJnYiIyIKmTJmCKVOm6P3s5mS9e/duk6/HxE5ERKLATWCIiIgciUg2gWFiJyIiURBLj52PuxERETkQ9tiJiEgcOBRPRETkWOxlON0UHIonIiJyIOyxExGROAhC/WFKezvAxE5ERKLAVfFERERkd9hjJyIiceCqeCIiIsch0dQfprS3BxyKJyIiciDssRMRkThwKJ6IiMhxiGVVPBM7ERGJg0ieY+ccOxERkQNhj52IiESBQ/FERESORCSL5zgUT0RE5EDYYyciIlHgUDwREZEj4ap4IiIisjfssRMRkShwKJ6IiMiRcFU8ERER2Rv22ImISBQ4FE9ERORINEL9YUp7O8DETkRE4sA5diIiIrI37LETEZEoSGDiHLvZIrEsJnYiIhIHvnmOiIiI7A177EREJAp83I2IiMiRcFU8ERER2Rv22ImISBQkggCJCQvgTGlrTUzsREQkDpo/D1Pa2wEOxRMRETkQ9tiJiEgUOBRPRETkSESyKp6JnYiIxIFvniMiIiJ7wx47ERGJAt88R83SIxNL8PgLxfAJqEPuaRmWvxWEY7962josMsEjD53C4yOPw8f7BnLzW2L5qmgcyw7UW9fHuwrPT8xEp45laNNaia3pXbF8VV8rR0z6PDz6AkaPOwsf3xrk5Xhh5dLuOP677y3rR/QuwXPTT6Bd6DWUlcjw9bqO+H5Le+3n9w/Px8w3jjRqN2rIcNTVOgMAnJw1eCruNIbEXoS3bw2ulsjwQ3ow/rumMwTBXvYisyKRDMUzsduRe/5xFQnzL+Ojf7XB8V898PD4Ury9LgfPDQlD8SU3W4dHTXDPwAtIeOYQPvrkLhzPDsDDD57G22/8iOde+geKSzwa1Xd10aBcKcN/N0bg0UeybRAx6TNo6CU899IxpLzfA9lHffDQqFzM/+AXvPDUEBRfadGofmDrKsz/4Fds39YO78+PRHjPMkyZ9Qcqyt1wYHeQtl7ldRdMHnuvTtuGpA4Ajz99FsNGXcCStyORe94LncPLMeNfR1BZ6YJtX3aw3A1Ts2bTOfakpCT07dsXXl5eCAgIwKhRo3Dq1ClbhtSsjX6+BDs2+GD7el/kn5Vh+dw2KL7sikcmlNo6NGqi0SNOYMf/OmH7D52Rf0mB5av6ori0BR55UP/fgyvFnli+qi9+2N0RlVX8Za65eHTseez8ph12fhOC/FwvfLI0AiVF7hj+aK7e+sMfvYDiK+74ZGkE8nO9sPObEGR82w6jx53XqScIwNUymc7xd10jruKXfa3w24FAFBW2wE+7gpD1qz86dy231K3aNYnG9MMe2DSx79mzB1OnTsXBgweRkZEBlUqF2NhYVFZW2jKsZsnFVYPOPauQucdLpzxzjxe6RfO/lz1ycVGjc8cyZP7eWqc880gQunUttlFUZCwXFw06hVUg61d/nfLDv/ojvEeZ3jZdI67i8M31f6lPyM7Of2UPd3c1Vm/6AZ9vycDc//yCDl0qdNqcOOqDXtElCAq+DgAI7VSBbr3KcOhn/VM5otcwFG/KYQdsmti3b9+OSZMmoXv37ujVqxdWr16NvLw8ZGZm6q1fU1MDpVKpc4iF3EcNZxegvER39qS82AXeASobRUWmkHvVwNlZQHm5bi+svEIG75bVNoqKjCVvWQtnFwHlZVKd8vIyKbx9avS28fap0VvfxUWAvGUtACA/1xNLFvbGglf74r25fVBb64z/LN+PoLbXtW2++qIT9mS0wYoNu7B177dYtmYvtqZ1wJ6MNma+SzJFSkoKQkNDIZPJEBUVhX379t2ybkFBAcaNG4ewsDA4OTlhxowZRl+vWT3uVlFR/9uoj4+P3s+TkpKgUCi0R3BwsDXDaxZu/oVRIoHdvDSB9Lt5kZME4Hdqh27+yiQS4bZfY6POX8Mfgz/LTx33xq4dbZFzVoHjv/vinTeicDnPEyMev6BtMvj+y7j3wYv4z7w+mD5pMBa/3Rujx53D0GH5pt2MoxLMcBgpLS0NM2bMwJw5c5CVlYVBgwZh2LBhyMvL01u/pqYG/v7+mDNnDnr16mX8BdGMErsgCEhMTMTdd9+NiIgIvXVmz56NiooK7ZGfL54/vMoyZ6hVgLe/bu9c4afC1WKugbRHymtSqNUSeHvf0ClXKKpxtUJ2i1bU3CjL3aBWSRr1zhXetY165Q2ulknh7atbv6V3DVQqCZQV+tdOCIIEp0+21OmxPzv1BL76ohP2/tAGuefl2LU9GFvSOuDxCWdMvCvH1PBKWVMOYy1evBhxcXGIj49HeHg4kpOTERwcjNTUVL3127dvj6VLl2LChAlQKBRNus9mk9hffPFFHD16FBs2bLhlHalUCrlcrnOIharOCWeOtkCfwdd0yvsMvoYThxqvnqbmT6VyxplzPujTq0CnvE+vApw46X+LVtTcqFROOHtKgci7dNdFRPYtRvYf+kcfTx7zRmTfm+rfVYwzJ1tCrb7VP8sCOnSuQFnpX7/0SWXqRiM+GrUETnzSzaJunhKuqdE/5VJbW4vMzEzExsbqlMfGxuLAgQMWi69ZJPZp06Zh27Zt2LVrF9q2bWvrcJqtTSv98NC4MsSOLUVwp2pMnncJAW3q8N3aWz8rS83bpm+64aGhZxF731kEt6nA5Gd+Q4BfJb7b2QUA8MxTh/HK9J902nRoX4YO7cvgLquDQl6NDu3L0K5tuQ2ipwab/9sBsSPy8MDDeQgOuYbnph+Df+ANpG8JAQBMTMhG4ptZ2vrpm9sjoNUNxE8/juCQa3jg4TzEjsjDpvV/PaL25LOn0KdfEVoFVaJD5wq89K/f0aGzEt9vDtHW+XV/IMZMPIO+A64goFUVYgYX4NGx5/Hz3lbWu3l7YqbFc8HBwTrTwklJSXovV1JSArVajcBA3cWMgYGBKCwstNht2nQMVxAETJs2DZs3b8bu3bsRGhpqy3CavT3bvOHlrcZTM6/AJ0CF3FMyvPF0KIr4DLvd2vNTe3h51eCpJ47Wv6AmryXeWHgfiorrXzrk430D/n66Tz2kLv5O+/+7dCrDfYMvoLDIAxMTRls1dvrLvv+1gVxRhyefPQ0f3xrknvfC3Fn9UFxY/wy7j281/AP/mnK5UtACc1++C8+9dByPjL6A0hIpViyJ0HmG3dOzDtNeOwpvnxpUVrrg3GkFXpsyAKezvbV1li/pgaefO4kps/6AwrsGZSUyfL81BBtWdbHezdsTAabtqf7nSHx+fr7OiLFUqn/KpYFEojuEIghCozJzkgiC7dbvT5kyBevXr8fWrVsRFhamLVcoFHB3d79je6VSCYVCgSEYCReJqyVDpeagf09bR0BW5FJYbusQyApUmhr8kPsxKioqLDa92pAr7ot8HS7OTV+/olJX48esdwyOtba2Fi1atMBXX32FRx99VFv+0ksv4ciRI9izZ89t2w8ZMgS9e/dGcnKyUXHadCg+NTUVFRUVGDJkCFq3bq090tLSbBkWERGRydzc3BAVFYWMjAyd8oyMDAwYMMBi17X5UDwREZFVCDDxXfHGN0lMTMT48eMRHR2NmJgYrFy5Enl5eUhISABQ/7TXpUuXsHbtWm2bI0eOAACuX7+O4uJiHDlyBG5ubujWrZtB1+RzUkREJA422ARmzJgxKC0txYIFC1BQUICIiAikp6cjJKR+EWRBQUGjZ9ojIyO1/z8zMxPr169HSEgILly4YNA1mdiJiIgsaMqUKZgyZYrez9asWdOozNTRbCZ2IiISBw3+esNfU9vbASZ2IiIShaa+Pe7v7e1Bs3hBDREREZkHe+xERCQONlg8ZwtM7EREJA4iSewciiciInIg7LETEZE4iKTHzsRORETiwMfdiIiIHAcfdyMiIiK7wx47ERGJA+fYiYiIHIhGACQmJGeNfSR2DsUTERE5EPbYiYhIHDgUT0RE5EhMTOywj8TOoXgiIiIHwh47ERGJA4fiiYiIHIhGgEnD6VwVT0RERNbGHjsREYmDoKk/TGlvB5jYiYhIHDjHTkRE5EA4x05ERET2hj12IiISBw7FExERORABJiZ2s0ViURyKJyIiciDssRMRkThwKJ6IiMiBaDQATHgWXWMfz7FzKJ6IiMiBsMdORETiwKF4IiIiByKSxM6heCIiIgfCHjsREYmDSF4py8RORESiIAgaCCbs0GZKW2tiYiciInEQBNN63ZxjJyIiImtjj52IiMRBMHGO3U567EzsREQkDhoNIDFhntxO5tg5FE9ERORA2GMnIiJx4FA8ERGR4xA0GggmDMXby+NuHIonIiJyIOyxExGROHAonoiIyIFoBEDi+ImdQ/FEREQOhD12IiISB0EAYMpz7PbRY2diJyIiURA0AgQThuIFJnYiIqJmRNDAtB47H3cjIiISvZSUFISGhkImkyEqKgr79u27bf09e/YgKioKMpkMHTp0wPLly426HhM7ERGJgqARTD6MlZaWhhkzZmDOnDnIysrCoEGDMGzYMOTl5emtn5OTg+HDh2PQoEHIysrCv/71L0yfPh0bN240+JpM7EREJA6CxvTDSIsXL0ZcXBzi4+MRHh6O5ORkBAcHIzU1VW/95cuXo127dkhOTkZ4eDji4+Px7LPP4v333zf4mnY9x96wkEGFOpPeOUB2QlVt6wjImjQ1to6ArEClqQVgnYVppuYKFeoAAEqlUqdcKpVCKpU2ql9bW4vMzEy8/vrrOuWxsbE4cOCA3mv8/PPPiI2N1Sl78MEH8dlnn6Gurg6urq53jNOuE/u1a9cAAPuRbuNIyCp+22rrCIjIQq5duwaFQmGRc7u5uaFVq1bYX2h6rvD09ERwcLBO2dy5czFv3rxGdUtKSqBWqxEYGKhTHhgYiMLCQr3nLyws1FtfpVKhpKQErVu3vmOMdp3Yg4KCkJ+fDy8vL0gkEluHYzVKpRLBwcHIz8+HXC63dThkQfyuxUOs37UgCLh27RqCgoIsdg2ZTIacnBzU1taafC5BEBrlG3299b+7ub6+c9ypvr7yW7HrxO7k5IS2bdvaOgybkcvlovoHQMz4XYuHGL9rS/XU/04mk0Emk1n8On/n5+cHZ2fnRr3zoqKiRr3yBq1atdJb38XFBb6+vgZdl4vniIiILMDNzQ1RUVHIyMjQKc/IyMCAAQP0tomJiWlUf+fOnYiOjjZofh1gYiciIrKYxMREfPrpp1i1ahWys7Mxc+ZM5OXlISEhAQAwe/ZsTJgwQVs/ISEBubm5SExMRHZ2NlatWoXPPvsMs2bNMviadj0UL1ZSqRRz586947wO2T9+1+LB79oxjRkzBqWlpViwYAEKCgoQERGB9PR0hISEAAAKCgp0nmkPDQ1Feno6Zs6ciY8//hhBQUFYtmwZHnvsMYOvKRHs5eW3REREdEcciiciInIgTOxEREQOhImdiIjIgTCxExERORAmdjtj7PZ/ZJ/27t2LESNGICgoCBKJBFu2bLF1SGQhSUlJ6Nu3L7y8vBAQEIBRo0bh1KlTtg6L7BgTux0xdvs/sl+VlZXo1asXPvroI1uHQha2Z88eTJ06FQcPHkRGRgZUKhViY2NRWVlp69DITvFxNzvSr18/9OnTR2e7v/DwcIwaNQpJSUk2jIwsSSKRYPPmzRg1apStQyErKC4uRkBAAPbs2YPBgwfbOhyyQ+yx24mG7f9u3s7vdtv/EZH9qaioAAD4+PjYOBKyV0zsdqIp2/8RkX0RBAGJiYm4++67ERERYetwyE7xlbJ2xtjt/4jIfrz44os4evQo9u/fb+tQyI4xsduJpmz/R0T2Y9q0adi2bRv27t0r6u2oyXQcircTTdn+j4iaP0EQ8OKLL2LTpk348ccfERoaauuQyM6xx25HEhMTMX78eERHRyMmJgYrV67U2f6PHMf169dx9uxZ7c85OTk4cuQIfHx80K5dOxtGRuY2depUrF+/Hlu3boWXl5d2VE6hUMDd3d3G0ZE94uNudiYlJQXvvfeedvu/JUuW8JEYB7R7927ce++9jconTpyINWvWWD8gsphbrZFZvXo1Jk2aZN1gyCEwsRMRETkQzrETERE5ECZ2IiIiB8LETkRE5ECY2ImIiBwIEzsREZEDYWInIiJyIEzsREREDoSJnYiIyIEwsROZaN68eejdu7f250mTJmHUqFFWj+PChQuQSCQ4cuTILeu0b98eycnJBp9zzZo1aNmypcmxSSQSbNmyxeTzENGdMbGTQ5o0aRIkEgkkEglcXV3RoUMHzJo1C5WVlRa/9tKlSw1+7ashyZiIyBjcBIYc1kMPPYTVq1ejrq4O+/btQ3x8PCorK5Gamtqobl1dHVxdXc1yXYVCYZbzEBE1BXvs5LCkUilatWqF4OBgjBs3Dk899ZR2OLhh+HzVqlXo0KEDpFIpBEFARUUFnn/+eQQEBEAul+O+++7D77//rnPed955B4GBgfDy8kJcXByqq6t1Pr95KF6j0eDdd99Fp06dIJVK0a5dOyxcuBAAtFt0RkZGQiKRYMiQIdp2q1evRnh4OGQyGbp27YqUlBSd6/z666+IjIyETCZDdHQ0srKyjP5vtHjxYvTo0QMeHh4IDg7GlClTcP369Ub1tmzZgi5dukAmk+GBBx5Afn6+zufffPMNoqKiIJPJ0KFDB8yfPx8qlcroeIjIdEzsJBru7u6oq6vT/nz27Fl8+eWX2Lhxo3Yo/OGHH0ZhYSHS09ORmZmJPn36YOjQoSgrKwMAfPnll5g7dy4WLlyIQ4cOoXXr1o0S7s1mz56Nd999F2+++SZOnDiB9evXIzAwEEB9cgaAH374AQUFBdi0aRMA4JNPPsGcOXOwcOFCZGdnY9GiRXjzzTfx+eefAwAqKyvxyCOPICwsDJmZmZg3bx5mzZpl9H8TJycnLFu2DMeOHcPnn3+OH3/8Ea+++qpOnaqqKixcuBCff/45fvrpJyiVSowdO1b7+Y4dO/D0009j+vTpOHHiBFasWIE1a9Zof3khIisTiBzQxIkThZEjR2p//uWXXwRfX1/hiSeeEARBEObOnSu4uroKRUVF2jr/+9//BLlcLlRXV+ucq2PHjsKKFSsEQRCEmJgYISEhQefzfv36Cb169dJ7baVSKUilUuGTTz7RG2dOTo4AQMjKytIpDw4OFtavX69T9u9//1uIiYkRBEEQVqxYIfj4+AiVlZXaz1NTU/We6+9CQkKEJUuW3PLzL7/8UvD19dX+vHr1agGAcPDgQW1Zdna2AED45ZdfBEEQhEGDBgmLFi3SOc8XX3whtG7dWvszAGHz5s23vC4RmQ/n2Mlhffvtt/D09IRKpUJdXR1GjhyJDz/8UPt5SEgI/P39tT9nZmbi+vXr8PX11TnPjRs3cO7cOQBAdnY2EhISdD6PiYnBrl279MaQnZ2NmpoaDB061OC4i4uLkZ+fj7i4ODz33HPacpVKpZ2/z87ORq9evdCiRQudOIy1a9cuLFq0CCdOnIBSqYRKpUJ1dTUqKyvh4eEBAHBxcUF0dLS2TdeuXdGyZUtkZ2fjrrvuQmZmJn777TedHrparUZ1dTWqqqp0YiQiy2NiJ4d17733IjU1Fa6urggKCmq0OK4hcTXQaDRo3bo1du/e3ehcTX3ky93d3eg2Go0GQP1wfL9+/XQ+c3Z2BgAIgtCkeP4uNzcXw4cPR0JCAv7973/Dx8cH+/fvR1xcnM6UBVD/uNrNGso0Gg3mz5+P0aNHN6ojk8lMjpOIjMPETg7Lw8MDnTp1Mrh+nz59UFhYCBcXF7Rv315vnfDwcBw8eBATJkzQlh08ePCW5+zcuTPc3d3xv//9D/Hx8Y0+d3NzA1Dfw20QGBiINm3a4Pz583jqqaf0nrdbt2744osvcOPGDe0vD7eLQ59Dhw5BpVLhgw8+gJNT/XKbL7/8slE9lUqFQ4cO4a677gIAnDp1CuXl5ejatSuA+v9up06dMuq/NRFZDhM70Z/uv/9+xMTEYNSoUXj33XcRFhaGy5cvIz09HaNGjUJ0dDReeuklTJw4EdHR0bj77ruxbt06HD9+HB06dNB7TplMhtdeew2vvvoq3NzcMHDgQBQXF+P48eOIi4tDQEAA3N3dsX37drRt2xYymQwKhQLz5s3D9OnTIZfLMWzYMNTU1ODQoUO4evUqEhMTMW7cOMyZMwdxcXF44403cOHCBbz//vtG3W/Hjh2hUqnw4YcfYsSIEfjpp5+wfPnyRvVcXV0xbdo0LFu2DK6urnjxxRfRv39/baJ/66238MgjjyA4OBiPP/44nJyccPToUfzxxx94++23jf8iiMgkXBVP9CeJRIL09HQMHjwYzz77LLp06YKxY8fiwoUL2lXsY8aMwVtvvYXXXnsNUVFRyM3NxQsvvHDb87755pt4+eWX8dZbbyE8PBxjxoxBUVERgPr562XLlmHFihUICgrCyJEjAQDx8fH49NNPsWbNGvTo0QP33HMP1qxZo308ztPTE9988w1OnDiByMhIzJkzB++++65R99u7d28sXrwY7777LiIiIrBu3TokJSU1qteiRQu89tprGDduHGJiYuDu7o7//ve/2s8ffPBBfPvtt8jIyEDfvn3Rv39/LF68GCEhIUbFQ0TmIRHMMVlHREREzQJ77ERERA6EiZ2IiMiBMLETERE5ECZ2IiIiB8LETkRE5ECY2ImIiBwIEzsREZEDYWInIiJyIEzsREREDoSJnYiIyIEwsRMRETmQ/we0bwIo16c7OwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123, stratify=y)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predicted = log_reg.predict(X_test)\n",
    "  \n",
    "cm = confusion_matrix(y_test, y_predicted)/len(y_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "# Print the performance metrics\n",
    "print('Accuracy score test set: ', accuracy_score(y_test, y_predicted))\n",
    "print('Confusion matrix test set: \\n', disp.plot())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "307f742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 predicted probabilities of class 0:  [0.01689667 0.01477306 0.01596531 0.98222074 0.01611824 0.01636063\n",
      " 0.98400201 0.01689667 0.9952779  0.99146392]\n",
      "First 10 predicted probabilities of class 1:  [0.5058388  0.79050973 0.67661928 0.00918884 0.49915885 0.44035276\n",
      " 0.00775296 0.5058388  0.00228231 0.00440969]\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=321)\n",
    "\n",
    "# Train a logistic regression\n",
    "log_reg = LogisticRegression(max_iter=500).fit(X_train, y_train)\n",
    "\n",
    "# Predict the probability of the 0 class\n",
    "prob_0 = log_reg.predict_proba(X_test)[:, 0]\n",
    "# Predict the probability of the 1 class\n",
    "prob_1 = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"First 10 predicted probabilities of class 0: \", prob_0[:10])\n",
    "print(\"First 10 predicted probabilities of class 1: \", prob_1[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869a434",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eba39440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 Word cloud and feature creation\n",
    "\n",
    "# # Create and generate a word cloud image\n",
    "# cloud_positives = WordCloud(background_color='white').generate(positive_reviews)\n",
    " \n",
    "# # Display the generated wordcloud image\n",
    "# plt.imshow(cloud_positives, interpolation='bilinear') \n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# # Don't forget to show the final image\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c066c7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 Word cloud and feature creation\n",
    "\n",
    "# # Tokenize each item in the review column\n",
    "# word_tokens = [word_tokenize(review) for review in reviews.review]\n",
    "\n",
    "# # Create an empty list to store the length of the reviews\n",
    "# len_tokens = []\n",
    "\n",
    "# # Iterate over the word_tokens list and determine the length of each item\n",
    "# for i in range(len(word_tokens)):\n",
    "#      len_tokens.append(len(word_tokens[i]))\n",
    "\n",
    "# # Create a new feature for the lengh of each review\n",
    "# reviews['n_words'] = len_tokens \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0fa03146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2 Building a vectorizer\n",
    "\n",
    "# # Import the TfidfVectorizer and default list of English stop words\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS \n",
    "\n",
    "# # Build the vectorizer\n",
    "# vect = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 2), max_features=200, token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b').fit(reviews.review)\n",
    "# # Create sparse matrix from the vectorizer\n",
    "# X = vect.transform(reviews.review)\n",
    "\n",
    "# # Create a DataFrame\n",
    "# reviews_transformed = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\n",
    "# print('Top 5 rows of the DataFrame: \\n', reviews_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "16794974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Building a classifier\n",
    "\n",
    "# # Define X and y\n",
    "# y = reviews_transformed.score\n",
    "# X = reviews_transformed.drop('score', axis=1)\n",
    "\n",
    "# # Train/test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=456)\n",
    "\n",
    "# # Train a logistic regression\n",
    "# log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "# # Predict the labels\n",
    "# y_predicted = log_reg.predict(X_test)\n",
    "\n",
    "# # Print accuracy score and confusion matrix on test set\n",
    "# print('Accuracy on the test set: ', accuracy_score(y_test, y_predicted))\n",
    "# print(confusion_matrix(y_test, y_predicted)/len(y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
